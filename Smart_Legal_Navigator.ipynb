{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilTaObrt9IvH",
        "outputId": "6cf7e192-9ae9-4aca-ba96-387dbf3c2d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pMRvWI0dffI",
        "outputId": "e999c98a-8605-4e85-83bf-1bcf50c34244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gTTS) (2.32.4)\n",
            "Collecting click<8.2,>=7.1 (from gTTS)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2025.10.5)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: click, gTTS\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "Successfully installed click-8.1.8 gTTS-2.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gTTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQIdSPw2dflI",
        "outputId": "0ab4314d-2497-4aa4-b6a3-b8edddf74e28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyttsx3\n",
            "  Downloading pyttsx3-2.99-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading pyttsx3-2.99-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pyttsx3\n",
            "Successfully installed pyttsx3-2.99\n"
          ]
        }
      ],
      "source": [
        "pip install pyttsx3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utAyzOFGihbI",
        "outputId": "aeb5e1a6-aeb1-4b7c-d7b8-7ddbb4dd2605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Collecting playsound\n",
            "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gTTS) (2.32.4)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2025.10.5)\n",
            "Building wheels for collected packages: playsound\n",
            "  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7020 sha256=7bdae97f9f89e9f096c130347ff76e6e1432f1505b56232fda6a716c9d9a6945\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/42/ff/7c587bae55eec67b909ca316b250d9b4daedbf272a3cbeb907\n",
            "Successfully built playsound\n",
            "Installing collected packages: playsound\n",
            "Successfully installed playsound-1.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install gTTS playsound transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdNXMDniUpJX",
        "outputId": "cf5a495f-998a-4532-eb02-bde84f08fa7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gtts) (2.32.4)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "pip install gtts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2lHjFVJUswI",
        "outputId": "1daa4655-39df-448c-852a-649f098fb3e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gTTS imported successfully!\n"
          ]
        }
      ],
      "source": [
        "from gtts import gTTS\n",
        "print(\"gTTS imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1vfLBiqeb3y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uSIT7nDa6NY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeaQ6626R57i",
        "outputId": "1604c24b-b831-49fc-8f83-af135d0961e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJDieHz0VL1J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_2QLmVsVPB5",
        "outputId": "d37e098c-7fac-4ad5-fb78-e7b3b11e9710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529,
          "referenced_widgets": [
            "2dc266b28c734a938c800be0ead84a65",
            "6225b685385640cba44aa19243fe818c",
            "c8f5d0ce8faf4248a55397ec2e8a67cf",
            "ed4247b86ffe4db6ba1bab72ccb47165",
            "b853d6a1f086406ab951d0040c601603",
            "879a3fa37615474085ea1c00b7bf6356",
            "3d39ae8cc9fa4fab9b96decea548e89a",
            "ed8f442694564abd915094745aa2a8b9",
            "d235eaee694748718955e86791b3334b",
            "db36c2fd6b72442ebc1fd0f24d6b5724",
            "c4b9833be64c4bd187b21958473c0bd3",
            "dd5f921278da4d30b7dea85e0d549f9e",
            "2312e76ca87b40b1a5068b13ae9f86a1",
            "48291020719f43db9b7bbbff13728147",
            "e7c5f4be346d49919cabf2b09eb19440",
            "3b9310f4aab74b05b45f95b913116f01",
            "8e8491cd4ee1471094733104e8f79f44",
            "b0c4d6eeae67487eb7ed181c18e93fcb",
            "bdbda4372f9f4516897d13373258b2df",
            "87de80df0ec749479f584f7894df6d36",
            "07bdc163f076437090841d4360dae9cf",
            "762002af13a94fe4897240599391f097",
            "cd6524d43c694659a055287bb6fc1080",
            "bce5aebd926d41f195562108b2cdb1b0",
            "66e6f9f9eee84e2fa8bbcf674be1efa7",
            "4ca4cadf5d044777994becef379b0f28",
            "6386c07cf04e4ee2963ab08331656612",
            "094c44eba03549b69dc30436881fdecc",
            "c1476d2312034d69a906a984b6e720b2",
            "d782239068ae496ba5eb8edf8bf9dd0f",
            "3a3db46550264d03a0e080e190ddf7f2",
            "fa8d75ee30b2490386a85a3383a4bcbe",
            "86b7d4931f0c491293fae2fd85479ec5",
            "a89381ca326c4f619318a2142f547928",
            "4f1d18c42a9f40a985e468fe7f87cd9b",
            "f9a8af2dc193429aaa0e541f9c8068dd",
            "1d560902e88141ac9812808c91696a4f",
            "4aa8208f259d4dabb29b36a0dd2f0d8f",
            "a9d12d2a1ef0493b9c929e50c0f8f397",
            "31baf0d747964e95a752678ac9af5801",
            "b20e26372e4148f18a1998159331bfbf",
            "3fe5530f92334086915795571dafc732",
            "6238a8920bef4e23989f0c7cfafd7280",
            "fa80e3c612804687bdd9cf6ccf9ae453",
            "9f1581138b6a4d3bb95bd0e6e9de1d0a",
            "af6f14bba8524fa2877ae2712b6680f7",
            "614a735ad83a4f04af6df7d54b563868",
            "4b5532a6138f4519855f817c61bf0f8f",
            "5e639e0a1e374de19ed2bbadc47b4e8a",
            "98c131e903db4fed89dcbd2bbeb56839",
            "7984a58e7f7d4c6bb3e4b3e4d8fee480",
            "9913a1ab84fb49b6aaa3a08518f0d471",
            "968c1bd1e50c475ca89603458ceb71d7",
            "fe67a366f4114dd4969844e6c54fabaf",
            "0c5d67417a8145bd82c5c199388ebf46"
          ]
        },
        "id": "Notsp9PyaMt8",
        "outputId": "df6d20a7-4742-4cea-b562-67bda8dba463"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dc266b28c734a938c800be0ead84a65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd5f921278da4d30b7dea85e0d549f9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd6524d43c694659a055287bb6fc1080",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a89381ca326c4f619318a2142f547928",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f1581138b6a4d3bb95bd0e6e9de1d0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1444496174.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Get the model's prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Example text\n",
        "text = \"Legal acts and regulations are critical to ensure compliance with the law.\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Get the model's prediction\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Get the predicted class (the one with the highest score)\n",
        "predicted_class = outputs.logits.argmax().item()\n",
        "\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtvbvtXZaj88"
      },
      "outputs": [],
      "source": [
        "pip install transformers torch pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwKl2IKJZTPO"
      },
      "outputs": [],
      "source": [
        "pip install transformers torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn6GpBeRnoT7"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import json\n",
        "\n",
        "# Paths to your datasets\n",
        "file_paths = {\n",
        "    \"/content/reduced_ipc_qa.json\"\n",
        "\n",
        "}\n",
        "\n",
        "# Load Pretrained Model and Tokenizer\n",
        "model_name = \"bert-base-uncased\"  # Use a BERT model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Create a pipeline for Question Answering\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Function to process the dataset and answer questions\n",
        "def process_dataset(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "    results = []\n",
        "    for idx, entry in enumerate(data):\n",
        "        question = entry.get(\"question\", \"\").strip()\n",
        "        context = entry.get(\"answer\", \"\").strip()  # Assuming the context is in the \"answer\" field\n",
        "        if question and context:\n",
        "            try:\n",
        "                result = qa_pipeline({\"question\": question, \"context\": context})\n",
        "                results.append({\n",
        "                    \"question\": question,\n",
        "                    \"context\": context,\n",
        "                    \"predicted_answer\": result[\"answer\"]\n",
        "                })\n",
        "                print(f\"Q: {question}\\nA: {result['answer']}\\n\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing question {idx + 1} in {file_path}: {e}\")\n",
        "    return results\n",
        "\n",
        "# Process each file and combine results\n",
        "all_results = []\n",
        "for dataset_name, file_path in file_paths.items():\n",
        "    print(f\"\\nProcessing dataset: {dataset_name}\\n\")\n",
        "    dataset_results = process_dataset(file_path)\n",
        "    all_results.extend(dataset_results)\n",
        "\n",
        "# Save combined results to a single JSON file\n",
        "output_file = \"/content/all_legal_qa_results.json\"\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(all_results, f, indent=4)\n",
        "\n",
        "print(f\"All results saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRKttSJd-Nrs"
      },
      "outputs": [],
      "source": [
        "!pip install gradio googletrans==4.0.0-rc1 SpeechRecognition pyttsx3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWOt160A_3Xc"
      },
      "outputs": [],
      "source": [
        "!pip install gradio googletrans==4.0.0-rc1 SpeechRecognition gtts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNT2tY0o-TIk"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4PojoKj-4OP"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from googletrans import Translator\n",
        "import gtts\n",
        "\n",
        "# Initialize modules\n",
        "recognizer = sr.Recognizer()\n",
        "translator = Translator()\n",
        "\n",
        "# Function to process audio input\n",
        "def process_audio(audio_file, target_language):\n",
        "    try:\n",
        "        with sr.AudioFile(audio_file) as source:\n",
        "            audio = recognizer.record(source)\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        translated_text = translator.translate(text, dest=target_language).text\n",
        "\n",
        "        # Generate audio using gTTS\n",
        "        tts = gtts.gTTS(translated_text, lang=target_language)\n",
        "        tts.save(\"response.mp3\")\n",
        "\n",
        "        return text, translated_text, \"response.mp3\"\n",
        "    except Exception as e:\n",
        "        return \"Error: \" + str(e), \"Error\", None\n",
        "\n",
        "# Function to process text input\n",
        "def process_text(input_text, target_language):\n",
        "    try:\n",
        "        translated_text = translator.translate(input_text, dest=target_language).text\n",
        "\n",
        "        # Generate audio using gTTS\n",
        "        tts = gtts.gTTS(translated_text, lang=target_language)\n",
        "        tts.save(\"response.mp3\")\n",
        "\n",
        "        return translated_text, \"response.mp3\"\n",
        "    except Exception as e:\n",
        "        return \"Error: \" + str(e), None\n",
        "\n",
        "# Chatbot function\n",
        "def chatbot_ui(audio_path, text, language):\n",
        "    if audio_path is not None:\n",
        "        user_text, translated_text, response_audio = process_audio(audio_path, language)\n",
        "        return f\"User: {user_text}\\nBot (translated): {translated_text}\", response_audio\n",
        "    elif text:\n",
        "        translated_text, response_audio = process_text(text, language)\n",
        "        return f\"User: {text}\\nBot (translated): {translated_text}\", response_audio\n",
        "    else:\n",
        "        return \"Please provide an audio or text input.\", None\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=chatbot_ui,\n",
        "    inputs=[\n",
        "        gr.Audio(type=\"filepath\", label=\"Upload Audio File\"),\n",
        "        gr.Textbox(label=\"Or Type Your Message\"),\n",
        "        gr.Dropdown(\n",
        "            choices=[\"en\", \"hi\", \"es\", \"fr\", \"de\", \"zh-cn\"],\n",
        "            label=\"Select Target Language\",\n",
        "            value=\"en\",\n",
        "        ),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Conversation\"),\n",
        "        gr.Audio(label=\"Bot Response\"),\n",
        "    ],\n",
        "    title=\"Chatbot with Language Translator and Voice Assistant\",\n",
        "    description=\"Upload an audio file or type your message, and the chatbot will translate and respond with voice output.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-96XrWlMELig"
      },
      "outputs": [],
      "source": [
        "interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ7IRfsXESVC"
      },
      "outputs": [],
      "source": [
        "!pip install gradio googletrans==4.0.0-rc1 SpeechRecognition gtts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nArOm3bqEYzm"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebMoE1lhEdf5"
      },
      "outputs": [],
      "source": [
        "# Install ngrok\n",
        "!pip install pyngrok\n",
        "\n",
        "# Set your ngrok authtoken\n",
        "!ngrok authtoken 2rLdyx6k5Fegfzce6hyibHvpiXn_3krx3zkTgepGq6ZQ17Sy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbiWkyNAGtvb"
      },
      "outputs": [],
      "source": [
        "public_url = ngrok.connect(7861)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS_zUVhvGtr6"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aduFil-tGteW"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y httpcore\n",
        "!pip install httpcore==0.15.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94PNVnLhFDen"
      },
      "outputs": [],
      "source": [
        "!pip install translate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ebk88IK_IYV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdWjUkQwH_aj"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "from translate import Translator\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "# Function to process chatbot inputs\n",
        "def chatbot_ui(audio_file, text_input, target_language):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Initialize the translator\n",
        "    translator = Translator(to_lang=target_language)\n",
        "\n",
        "    # Handle audio file input\n",
        "    if audio_file:\n",
        "        try:\n",
        "            with sr.AudioFile(audio_file) as source:\n",
        "                audio = recognizer.record(source)\n",
        "                user_text = recognizer.recognize_google(audio)\n",
        "        except Exception as e:\n",
        "            user_text = f\"Error processing audio: {str(e)}\"\n",
        "    else:\n",
        "        user_text = text_input\n",
        "\n",
        "    # Translate user input to target language\n",
        "    try:\n",
        "        translated_text = translator.translate(user_text)\n",
        "    except Exception as e:\n",
        "        translated_text = f\"Error in translation: {str(e)}\"\n",
        "\n",
        "    # Generate audio response\n",
        "    try:\n",
        "        tts = gTTS(translated_text, lang=target_language)\n",
        "        audio_output_path = \"output_audio.mp3\"\n",
        "        tts.save(audio_output_path)\n",
        "    except Exception as e:\n",
        "        audio_output_path = None\n",
        "        translated_text += f\"\\nError generating audio: {str(e)}\"\n",
        "\n",
        "    return translated_text, audio_output_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRWCcfTYIDm4"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from translate import Translator\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "# Function to process chatbot inputs\n",
        "def chatbot_ui(audio_file, text_input, target_language):\n",
        "    recognizer = sr.Recognizer()\n",
        "    translator = Translator(to_lang=target_language)\n",
        "\n",
        "    if audio_file:\n",
        "        try:\n",
        "            with sr.AudioFile(audio_file) as source:\n",
        "                audio = recognizer.record(source)\n",
        "                user_text = recognizer.recognize_google(audio)\n",
        "        except Exception as e:\n",
        "            user_text = f\"Error processing audio: {str(e)}\"\n",
        "    else:\n",
        "        user_text = text_input\n",
        "\n",
        "    try:\n",
        "        translated_text = translator.translate(user_text)\n",
        "    except Exception as e:\n",
        "        translated_text = f\"Error in translation: {str(e)}\"\n",
        "\n",
        "    try:\n",
        "        tts = gTTS(translated_text, lang=target_language)\n",
        "        audio_output_path = \"output_audio.mp3\"\n",
        "        tts.save(audio_output_path)\n",
        "    except Exception as e:\n",
        "        audio_output_path = None\n",
        "        translated_text += f\"\\nError generating audio: {str(e)}\"\n",
        "\n",
        "    return translated_text, audio_output_path\n",
        "\n",
        "# Set up ngrok tunnel\n",
        "public_url = ngrok.connect(7861)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Define Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=chatbot_ui,\n",
        "    inputs=[\n",
        "        gr.Audio(type=\"filepath\", label=\"Upload Audio File\"),\n",
        "        gr.Textbox(label=\"Or Type Your Message\"),\n",
        "        gr.Dropdown(\n",
        "            choices=[\"en\", \"hi\", \"es\", \"fr\", \"de\", \"zh-cn\"],\n",
        "            label=\"Select Target Language\",\n",
        "            value=\"en\",\n",
        "        ),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Translated Text\"),\n",
        "        gr.Audio(label=\"Bot Response\"),\n",
        "    ],\n",
        "    title=\"Chatbot with Language Translator and Voice Assistant\",\n",
        "    description=\"Upload an audio file or type your message, and the chatbot will translate and respond with voice output.\"\n",
        ")\n",
        "\n",
        "# Launch Gradio app on a different port\n",
        "interface.launch(server_name=\"0.0.0.0\", server_port=7861)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnX9AEe0IuXo"
      },
      "outputs": [],
      "source": [
        "interface.launch(server_name=\"0.0.0.0\", server_port=7861, share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHK47754JlnT"
      },
      "outputs": [],
      "source": [
        "interface.launch(server_name=\"0.0.0.0\", server_port=7861, share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-fyNLk6IQPk"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y httpx httpcore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXZh6vbeISgg"
      },
      "outputs": [],
      "source": [
        "!pip install httpx==0.23.0\n",
        "!pip install httpcore==0.15.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obiHDwRYKEb5"
      },
      "outputs": [],
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-40AMlXJ9bK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from googletrans import Translator\n",
        "\n",
        "# Initialize the translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load datasets\n",
        "def load_datasets():\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json', 'r') as f1:\n",
        "        constitution_data = json.load(f1)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json', 'r') as f2:\n",
        "        crpc_data = json.load(f2)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/ipc_qa.json', 'r') as f3:\n",
        "        ipc_data = json.load(f3)\n",
        "    return constitution_data + crpc_data + ipc_data\n",
        "\n",
        "# Search the dataset for a response\n",
        "def find_response(question, dataset):\n",
        "    \"\"\"\n",
        "    Search the dataset for a question matching the user's query.\n",
        "    :param question: User's input query\n",
        "    :param dataset: Combined dataset\n",
        "    :return: Matched answer or a default message\n",
        "    \"\"\"\n",
        "    for entry in dataset:\n",
        "        if question.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return \"I'm sorry, I don't have an answer for that question.\"\n",
        "\n",
        "# Translate text\n",
        "def translate_text(text, target_language='en'):\n",
        "    \"\"\"\n",
        "    Translate text to the target language.\n",
        "    :param text: Text to be translated\n",
        "    :param target_language: Target language code (default is 'en' for English)\n",
        "    :return: Translated text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        translated = translator.translate(text, dest=target_language)\n",
        "        return translated.text\n",
        "    except Exception as e:\n",
        "        return f\"Translation error: {e}\"\n",
        "\n",
        "# Chatbot logic\n",
        "def chatbot_response(user_input, dataset, target_language='en'):\n",
        "    \"\"\"\n",
        "    Generate chatbot response with dataset integration and translation.\n",
        "    :param user_input: User's input text\n",
        "    :param dataset: Combined dataset\n",
        "    :param target_language: Language for the response\n",
        "    :return: Chatbot response in the target language\n",
        "    \"\"\"\n",
        "    response = find_response(user_input, dataset)\n",
        "    translated_response = translate_text(response, target_language)\n",
        "    return translated_response\n",
        "\n",
        "# Load the datasets\n",
        "combined_dataset = load_datasets()\n",
        "\n",
        "# Example usage\n",
        "user_question = \"What is India according to the Union and its Territory?\"\n",
        "response_language = 'ta'  # Translate to Tamil, for example\n",
        "bot_response = chatbot_response(user_question, combined_dataset, response_language)\n",
        "print(f\"Chatbot Response: {bot_response}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3O5Ikd-J9Xy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from googletrans import Translator\n",
        "\n",
        "# Initialize the translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load datasets\n",
        "def load_datasets():\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json', 'r') as f1:\n",
        "        constitution_data = json.load(f1)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json', 'r') as f2:\n",
        "        crpc_data = json.load(f2)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/updated_ipc_qa.json', 'r') as f3:\n",
        "        ipc_data = json.load(f3)\n",
        "    return constitution_data + crpc_data + ipc_data\n",
        "\n",
        "# Search the dataset for a response\n",
        "def find_response(question, dataset):\n",
        "    \"\"\"\n",
        "    Search the dataset for a question matching the user's query.\n",
        "    :param question: User's input query\n",
        "    :param dataset: Combined dataset\n",
        "    :return: Matched answer or a default message\n",
        "    \"\"\"\n",
        "    for entry in dataset:\n",
        "        if question.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return \"I'm sorry, I don't have an answer for that question.\"\n",
        "\n",
        "# Detect language and translate\n",
        "def detect_and_translate(text, target_language='en'):\n",
        "    \"\"\"\n",
        "    Detect the input language and translate it to the target language.\n",
        "    :param text: Input text\n",
        "    :param target_language: Target language code\n",
        "    :return: Translated text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        detected_language = translator.detect(text).lang\n",
        "        translated_text = translator.translate(text, src=detected_language, dest=target_language).text\n",
        "        return translated_text, detected_language\n",
        "    except Exception as e:\n",
        "        return f\"Error in translation: {e}\", None\n",
        "\n",
        "# Translate response to desired language\n",
        "def translate_response(response, target_language='en'):\n",
        "    \"\"\"\n",
        "    Translate chatbot response to the target language.\n",
        "    :param response: Chatbot response text\n",
        "    :param target_language: Language code for translation\n",
        "    :return: Translated text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return translator.translate(response, dest=target_language).text\n",
        "    except Exception as e:\n",
        "        return f\"Translation error: {e}\"\n",
        "\n",
        "# Chatbot logic\n",
        "def chatbot_response(user_input, dataset, output_language='en'):\n",
        "    \"\"\"\n",
        "    Generate chatbot response with dataset integration and multi-language support.\n",
        "    :param user_input: User's input text\n",
        "    :param dataset: Combined dataset\n",
        "    :param output_language: Language code for the chatbot's response\n",
        "    :return: Chatbot response in the desired language\n",
        "    \"\"\"\n",
        "    # Detect input language and translate to English\n",
        "    translated_input, input_language = detect_and_translate(user_input, target_language='en')\n",
        "\n",
        "    if input_language:\n",
        "        print(f\"Detected Input Language: {input_language}\")\n",
        "\n",
        "    # Find response from dataset\n",
        "    response_in_english = find_response(translated_input, dataset)\n",
        "\n",
        "    # Translate response to the desired output language\n",
        "    final_response = translate_response(response_in_english, output_language)\n",
        "    return final_response\n",
        "\n",
        "# Load the datasets\n",
        "combined_dataset = load_datasets()\n",
        "\n",
        "# Example usage\n",
        "user_question = \"இந்தியாவின் அரசியல் அமைப்பு என்ன?\"\n",
        "response_language = 'te'  # Translate response to Telugu, for example\n",
        "bot_response = chatbot_response(user_question, combined_dataset, response_language)\n",
        "print(f\"Chatbot Response: {bot_response}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3tMQBKtLwdr"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yzgge9NMpYF"
      },
      "outputs": [],
      "source": [
        "!pip install deep-translator gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnK-v6B_Nfnd"
      },
      "outputs": [],
      "source": [
        "!pip install deep-translator gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lou3CeY-MrUb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from deep_translator import GoogleTranslator\n",
        "import gradio as gr\n",
        "\n",
        "# Load datasets\n",
        "def load_datasets():\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json', 'r') as f1:\n",
        "        constitution_data = json.load(f1)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json', 'r') as f2:\n",
        "        crpc_data = json.load(f2)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/ipc_qa.json', 'r') as f3:\n",
        "        ipc_data = json.load(f3)\n",
        "    return constitution_data + crpc_data + ipc_data\n",
        "\n",
        "# Search the dataset for a response\n",
        "def find_response(question, dataset):\n",
        "    for entry in dataset:\n",
        "        if question.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return \"I'm sorry, I don't have an answer for that question.\"\n",
        "\n",
        "# Detect and translate the input\n",
        "def detect_and_translate_input(user_input, dataset, output_language):\n",
        "    try:\n",
        "        # Translate input to English for processing\n",
        "        translated_input = GoogleTranslator(source='auto', target='en').translate(user_input)\n",
        "        # Find the response in the dataset\n",
        "        response_in_english = find_response(translated_input, dataset)\n",
        "        # Translate response to the target language\n",
        "        translated_response = GoogleTranslator(source='en', target=output_language).translate(response_in_english)\n",
        "        return translated_response\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Load the datasets\n",
        "combined_dataset = load_datasets()\n",
        "\n",
        "# Define Gradio Interface\n",
        "def chat_interface(user_input, output_language):\n",
        "    return detect_and_translate_input(user_input, combined_dataset, output_language)\n",
        "\n",
        "# Gradio App with new components syntax\n",
        "interface = gr.Interface(\n",
        "    fn=chat_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Your Query\", placeholder=\"Type your question here...\"),\n",
        "        gr.Dropdown(\n",
        "            choices=[\n",
        "                \"en\", \"hi\", \"ta\", \"te\", \"kn\", \"bn\", \"gu\", \"mr\", \"pa\", \"ur\", \"ml\"\n",
        "            ],\n",
        "            label=\"Choose Output Language\",\n",
        "            value=\"en\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Chatbot Response\"),\n",
        "    title=\"Smart Legal Navigator\",\n",
        "    description=\"Ask questions related to the Indian Constitution, CRPC, or IPC. Choose your preferred language for the chatbot's response.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HWjWmJYJ9VU"
      },
      "outputs": [],
      "source": [
        "!pip install gradio speechrecognition pyttsx3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoNzKhSFPmLi"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00OiKKBfOupJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from deep_translator import GoogleTranslator\n",
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "import pyttsx3\n",
        "\n",
        "# Load datasets\n",
        "def load_datasets():\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json', 'r') as f1:\n",
        "        constitution_data = json.load(f1)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json', 'r') as f2:\n",
        "        crpc_data = json.load(f2)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/ipc_qa.json', 'r') as f3:\n",
        "        ipc_data = json.load(f3)\n",
        "    return constitution_data + crpc_data + ipc_data\n",
        "\n",
        "# Search the dataset for a response\n",
        "def find_response(question, dataset):\n",
        "    for entry in dataset:\n",
        "        if question.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return \"I'm sorry, I don't have an answer for that question.\"\n",
        "\n",
        "# Detect and translate the input\n",
        "def detect_and_translate_input(user_input, dataset, output_language):\n",
        "    try:\n",
        "        # Translate input to English for processing\n",
        "        translated_input = GoogleTranslator(source='auto', target='en').translate(user_input)\n",
        "        # Find the response in the dataset\n",
        "        response_in_english = find_response(translated_input, dataset)\n",
        "        # Translate response to the target language\n",
        "        translated_response = GoogleTranslator(source='en', target=output_language).translate(response_in_english)\n",
        "        return translated_response\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Convert speech to text\n",
        "def speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    try:\n",
        "        with sr.AudioFile(audio_file) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            return recognizer.recognize_google(audio_data)\n",
        "    except Exception as e:\n",
        "        return f\"Speech recognition error: {e}\"\n",
        "\n",
        "# Convert text to speech\n",
        "def text_to_speech(response_text):\n",
        "    engine = pyttsx3.init()\n",
        "    engine.say(response_text)\n",
        "    engine.runAndWait()\n",
        "\n",
        "# Combined Voice Chatbot Logic\n",
        "def voice_chatbot(audio_input, output_language):\n",
        "    # Convert voice to text\n",
        "    user_query = speech_to_text(audio_input)\n",
        "    if \"error\" in user_query.lower():\n",
        "        return user_query, None\n",
        "\n",
        "    # Get chatbot response\n",
        "    chatbot_response = detect_and_translate_input(user_query, combined_dataset, output_language)\n",
        "\n",
        "    # Convert response to speech\n",
        "    text_to_speech(chatbot_response)\n",
        "    return chatbot_response, chatbot_response\n",
        "\n",
        "# Load the datasets\n",
        "combined_dataset = load_datasets()\n",
        "\n",
        "# Gradio App with Voice Input and Output\n",
        "interface = gr.Interface(\n",
        "    fn=voice_chatbot,\n",
        "    inputs=[\n",
        "        gr.Audio(type=\"filepath\", label=\"Speak Your Query\"),  # Fixed input for audio\n",
        "        gr.Dropdown(\n",
        "            choices=[\n",
        "                \"en\", \"hi\", \"ta\", \"te\", \"kn\", \"bn\", \"gu\", \"mr\", \"pa\", \"ur\", \"ml\"\n",
        "            ],\n",
        "            label=\"Choose Output Language\",\n",
        "            value=\"en\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Chatbot Response\"),\n",
        "        gr.Audio(label=\"Voice Response\")\n",
        "    ],\n",
        "    title=\"Smart Legal Navigator\",\n",
        "    description=\"Speak your question into the microphone. The chatbot will process it and respond with voice and text.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDttpXV0UTHA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-NXIAChcNGO"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_mp3_with_ffmpeg(mp3_path, wav_path):\n",
        "    try:\n",
        "        # Command to convert MP3 to WAV using ffmpeg\n",
        "        command = [\n",
        "            \"ffmpeg\", \"-i\", mp3_path, \"-acodec\", \"pcm_s16le\", wav_path\n",
        "        ]\n",
        "\n",
        "        # Execute the command\n",
        "        subprocess.run(command, check=True)\n",
        "        print(f\"Conversion successful with ffmpeg: {wav_path}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error during conversion with ffmpeg: {e}\")\n",
        "\n",
        "# Attempt to convert using ffmpeg\n",
        "convert_mp3_with_ffmpeg(mp3_file_path, wav_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFmtcG81RI9x"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your zip file\n",
        "zip_file_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/audio_dataset.zip\"\n",
        "extract_dir = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/extracted_audio\"\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Extracted files to {extract_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaQoVD4fRwIS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VZndOZlSLbe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "extract_dir = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/extracted_audio\"\n",
        "\n",
        "# List files in the extracted directory\n",
        "extracted_files = os.listdir(extract_dir)\n",
        "print(extracted_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vABfDpluRnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory where the files were extracted\n",
        "extract_dir = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/extracted_audio\"\n",
        "\n",
        "# Recursively list all files in the extracted directory\n",
        "all_files = []\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        all_files.append(os.path.join(root, file))\n",
        "\n",
        "print(all_files)  # List all files found\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z32kYgUfcibo"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Path to the problematic MP3 file\n",
        "mp3_file_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/extracted_audio/audio_dataset/validation/validation_38.mp3\"\n",
        "wav_file_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/extracted_audio/audio_dataset/validation/validation_38_repaired.wav\"\n",
        "\n",
        "# Function to convert MP3 to WAV using ffmpeg\n",
        "def convert_mp3_with_ffmpeg(mp3_path, wav_path):\n",
        "    try:\n",
        "        # Command to convert MP3 to WAV using ffmpeg\n",
        "        command = [\n",
        "            \"ffmpeg\", \"-i\", mp3_path, \"-acodec\", \"pcm_s16le\", wav_path\n",
        "        ]\n",
        "\n",
        "        # Execute the command\n",
        "        subprocess.run(command, check=True)\n",
        "        print(f\"Conversion successful with ffmpeg: {wav_path}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error during conversion with ffmpeg: {e}\")\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(mp3_file_path):\n",
        "    print(f\"File found: {mp3_file_path}\")\n",
        "\n",
        "    # Attempt to convert using ffmpeg\n",
        "    convert_mp3_with_ffmpeg(mp3_file_path, wav_file_path)\n",
        "else:\n",
        "    print(f\"File not found: {mp3_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekcHqSE8Sz8Z"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcS3HulbTZ6z"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def fetch_legal_news():\n",
        "    url = \"https://www.livelaw.in/\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    articles = []\n",
        "    for item in soup.select('.story-title a'):  # Selector may vary for the site\n",
        "        title = item.get_text(strip=True)\n",
        "        link = item['href']\n",
        "        articles.append({'title': title, 'link': link})\n",
        "\n",
        "    return pd.DataFrame(articles)\n",
        "\n",
        "# Fetch and display news\n",
        "legal_news = fetch_legal_news()\n",
        "print(legal_news)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAHiyla_V8r5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def fetch_legal_news_from_api(api_key):\n",
        "    url = f\"https://newsapi.org/v2/everything?q=Indian+Law&apiKey={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    articles = []\n",
        "    if data['status'] == 'ok':\n",
        "        for article in data['articles']:\n",
        "            articles.append({\n",
        "                'title': article['title'],\n",
        "                'description': article['description'],\n",
        "                'url': article['url'],\n",
        "                'publishedAt': article['publishedAt']\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(articles)\n",
        "\n",
        "# Add your NewsAPI key here\n",
        "api_key = \"YOUR_NEWSAPI_KEY\"\n",
        "legal_news = fetch_legal_news_from_api(api_key)\n",
        "print(legal_news)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRxdTodAV8pe"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def get_latest_news():\n",
        "    news = fetch_legal_news()\n",
        "    return news.to_string(index=False)\n",
        "\n",
        "iface = gr.Interface(fn=get_latest_news,\n",
        "                     inputs=[],\n",
        "                     outputs=\"text\",\n",
        "                     title=\"Real-Time Legal News\",\n",
        "                     description=\"Fetch the latest updates on Indian law.\")\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN-FeSB3WOnP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5cOLQs2WOkx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load JSON dataset\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json\", \"r\") as file:\n",
        "    dataset = json.load(file)\n",
        "\n",
        "# Convert dataset to a list of Q&A pairs\n",
        "questions = [item[\"question\"] for item in dataset]\n",
        "answers = [item[\"answer\"] for item in dataset]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PADuJB5oXOIB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "\n",
        "# Load a pre-trained model and tokenizer\n",
        "model_name = \"deepset/roberta-base-squad2\"  # Q&A model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Create a Q&A pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQIE9GChXfyl"
      },
      "outputs": [],
      "source": [
        "# Test the model with a question\n",
        "sample_question = \"What is the penalty for rash driving?\"\n",
        "context = \" \".join(answers)  # Combine all answers as context for simplicity\n",
        "\n",
        "result = qa_pipeline({\n",
        "    \"question\": sample_question,\n",
        "    \"context\": context\n",
        "})\n",
        "\n",
        "print(\"Answer:\", result[\"answer\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJvmHAJXXfoz"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Prepare dataset for fine-tuning\n",
        "qa_data = {\"question\": questions, \"context\": answers, \"answers\": [{\"text\": a, \"answer_start\": 0} for a in answers]}\n",
        "hf_dataset = Dataset.from_dict(qa_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziAQy3mCYK-5"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training and evaluation sets\n",
        "train_size = int(0.8 * len(hf_dataset))  # 80% training\n",
        "train_dataset = hf_dataset.select(range(train_size))\n",
        "eval_dataset = hf_dataset.select(range(train_size, len(hf_dataset)))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",  # Enable evaluation\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,  # Provide evaluation dataset\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwDzC8nYYK45"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",  # Updated parameter\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5LCTR4fYK2f"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"no\",  # No evaluation\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiAnZAfHdHUs"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "# File paths\n",
        "file_paths = [\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/updated_ipc_qa.json\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json\",\n",
        "]\n",
        "\n",
        "# Load and combine datasets\n",
        "combined_data = []\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "        combined_data.extend(data)  # Combine all questions and answers\n",
        "\n",
        "# Convert combined JSON data into Hugging Face Dataset\n",
        "questions = [item[\"question\"] for item in combined_data]\n",
        "answers = [item[\"answer\"] for item in combined_data]\n",
        "qa_dataset = Dataset.from_dict({\n",
        "    \"question\": questions,\n",
        "    \"context\": answers,  # Using answers as context for simplicity\n",
        "    \"answers\": [{\"text\": a, \"answer_start\": 0} for a in answers],  # Dummy answer_start\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUnLpadBgDvF"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training and evaluation sets\n",
        "train_size = int(0.8 * len(qa_dataset))  # 80% training\n",
        "train_dataset = qa_dataset.select(range(train_size))\n",
        "eval_dataset = qa_dataset.select(range(train_size, len(qa_dataset)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm2LtK7qOx8z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPWbzaifOx0S"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWdpZ2IOeBsF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "# File paths\n",
        "file_paths = [\n",
        "    \"/content/reduced_legal_qa.json\",\n",
        "]\n",
        "\n",
        "# Load and combine datasets\n",
        "combined_data = []\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "        combined_data.extend(data)  # Combine all questions and answers\n",
        "\n",
        "# Load tokenizer\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Preprocess dataset\n",
        "def preprocess(example):\n",
        "    inputs = tokenizer(\n",
        "        example[\"question\"],\n",
        "        example[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # Find start and end positions of the answer in the context\n",
        "    start_char = example[\"answers\"][\"answer_start\"]\n",
        "    end_char = start_char + len(example[\"answers\"][\"text\"])\n",
        "    start_token = inputs.char_to_token(start_char)\n",
        "    end_token = inputs.char_to_token(end_char - 1)\n",
        "\n",
        "    # Handle cases where the tokenizer fails to map characters to tokens\n",
        "    if start_token is None or end_token is None:\n",
        "        start_token, end_token = 0, 0\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "        \"start_positions\": start_token,\n",
        "        \"end_positions\": end_token,\n",
        "    }\n",
        "\n",
        "# Convert JSON data into a Hugging Face Dataset\n",
        "qa_dataset = Dataset.from_list([\n",
        "    {\n",
        "        \"question\": item[\"question\"],\n",
        "        \"context\": item[\"answer\"],  # Assuming `answer` is the full context\n",
        "        \"answers\": {\"text\": item[\"answer\"], \"answer_start\": 0},  # Dummy start index\n",
        "    }\n",
        "    for item in combined_data\n",
        "])\n",
        "\n",
        "# Apply preprocessing\n",
        "qa_dataset = qa_dataset.map(preprocess, remove_columns=[\"question\", \"context\", \"answers\"])\n",
        "\n",
        "# Split dataset into training and evaluation sets\n",
        "train_size = int(0.8 * len(qa_dataset))  # 80% training\n",
        "train_dataset = qa_dataset.select(range(train_size))\n",
        "eval_dataset = qa_dataset.select(range(train_size, len(qa_dataset)))\n",
        "\n",
        "# Define training arguments\n",
        "from transformers import TrainingArguments, Trainer, AutoModelForQuestionAnswering\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    remove_unused_columns=False,  # Ensure no columns are ignored\n",
        ")\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEQA66Rn_cZc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now evaluate and calculate F1 and EM scores\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Evaluation Results: \", eval_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhH25CV-BdAu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    # Unpack the tuple: p contains logits and labels in the form of (predictions, labels)\n",
        "    logits, labels = p\n",
        "\n",
        "    # Extract start and end positions from the labels tuple\n",
        "    start_positions = labels[0]  # The second element of the tuple (start positions)\n",
        "\n",
        "    # Get the predicted start and end positions\n",
        "    start_preds = np.argmax(logits[0], axis=-1)  # logits[0] corresponds to start logits\n",
        "    end_preds = np.argmax(logits[1], axis=-1)  # logits[1] corresponds to end logits\n",
        "\n",
        "    # Calculate F1 scores for both start and end predictions\n",
        "    f1_start = f1_score(start_positions, start_preds, average='weighted')\n",
        "    f1_end = f1_score(labels[1], end_preds, average='weighted')\n",
        "\n",
        "    # Combined F1 score\n",
        "    f1_combined = (f1_start + f1_end) / 2\n",
        "\n",
        "    return {\n",
        "        'f1_start': f1_start,\n",
        "        'f1_end': f1_end,\n",
        "        'f1_combined': f1_combined\n",
        "    }\n",
        "\n",
        "# Make sure to pass this compute_metrics function to the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics  # Add compute_metrics here\n",
        ")\n",
        "\n",
        "# Run the evaluation and get the F1 score\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)  # This should now include F1 scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFpoYcngBIkN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of F1 scores (replace this with the actual F1 scores from each epoch)\n",
        "f1_scores = [0.60, 0.65, 0.70]  # Example F1 scores for each epoch\n",
        "\n",
        "# Plot the F1 scores\n",
        "def plot_f1_scores(f1_scores):\n",
        "    plt.plot(f1_scores, label='F1 Score', marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.title('F1 Score over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot F1 scores\n",
        "plot_f1_scores(f1_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieAmcq9kE6N4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# F1 scores (example values from your result)\n",
        "f1_combined = [0.816040072522783]  # Combined F1 score for the current evaluation\n",
        "\n",
        "# Plotting the F1 score (combined)\n",
        "def plot_f1(f1_scores):\n",
        "    plt.plot(f1_scores, label='F1 Score (Combined)', marker='o', color='b')\n",
        "    plt.xlabel('Evaluation')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.title('F1 Score (Combined) in Evaluation')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot F1 score\n",
        "plot_f1(f1_combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dzRFL9nE6Fi"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Evaluation results\n",
        "eval_f1_start = 0.899\n",
        "eval_f1_end = 0.733\n",
        "eval_f1_combined = 0.816\n",
        "\n",
        "# Create data for heatmap\n",
        "data = np.array([[eval_f1_start, eval_f1_end, eval_f1_combined]])\n",
        "\n",
        "# Plot heatmap\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "sns.heatmap(data, annot=True, cmap='YlGnBu', cbar=True, xticklabels=['Start F1', 'End F1', 'Combined F1'], yticklabels=['F1 Scores'])\n",
        "ax.set_title(\"F1 Score Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsOodVEegBKT"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otRYg4xsg_7S"
      },
      "outputs": [],
      "source": [
        "# Save the fine-tuned model and tokenizer\n",
        "model.save_pretrained(\"./fine_tuned_model\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBuDgEjmkoCW"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCrv7jpnk1zg"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install datasets transformers scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ1RROvElKZ8"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp1SB6eahdXa"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTcHyMorncnB"
      },
      "outputs": [],
      "source": [
        "# Print a sample from the dataset to check the structure\n",
        "print(dataset[0])\n",
        "print(dataset[1]) # Check the first example in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbDECSLbnf7n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json\"\n",
        "print(os.path.exists(file_path))  # This should return True if the file exists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PKW_zF3rDQB"
      },
      "outputs": [],
      "source": [
        "# Check if the directory exists\n",
        "print(os.listdir('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhZqrjlgnf4Q"
      },
      "outputs": [],
      "source": [
        "import json  # Make sure this import is included\n",
        "\n",
        "file_paths = [\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/ipc_qa.json\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json\",\n",
        "]\n",
        "\n",
        "combined_data = []\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "        combined_data.extend(data)  # Combine all questions and answers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qkcjVEXqnL2"
      },
      "outputs": [],
      "source": [
        "pip install requests beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmcGzJdXsxvf"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Example function to scrape live updates from a website\n",
        "def get_latest_legal_updates():\n",
        "    url = \"https://www.livelaw.in/\"  # Replace with the actual law website\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Assuming articles are in <h2> tags (adjust based on website structure)\n",
        "    updates = soup.find_all('h2')\n",
        "\n",
        "    # Extracting titles of legal updates\n",
        "    legal_updates = [update.text.strip() for update in updates]\n",
        "\n",
        "    return legal_updates\n",
        "\n",
        "# Fetch latest updates\n",
        "latest_updates = get_latest_legal_updates()\n",
        "for i, update in enumerate(latest_updates[:5]):\n",
        "    print(f\"{i+1}. {update}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFsf6HGrszkY"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "def answer_question(question, context):\n",
        "    inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, padding=True, max_length=384)\n",
        "    outputs = model(**inputs)\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "\n",
        "    start_index = start_scores.argmax()\n",
        "    end_index = end_scores.argmax()\n",
        "\n",
        "    answer_tokens = inputs.input_ids[0][start_index:end_index+1]\n",
        "    answer = tokenizer.decode(answer_tokens)\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Example of integrating legal updates\n",
        "legal_updates_context = \" \".join(get_latest_legal_updates())  # Combine all updates into context\n",
        "\n",
        "# Get a question and get an answer\n",
        "question = \"What are the latest updates in Indian law?\"\n",
        "answer = answer_question(question, legal_updates_context)\n",
        "\n",
        "print(f\"Answer: {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEPkOkYl2QCu"
      },
      "outputs": [],
      "source": [
        "pip install requests beautifulsoup4 sqlite3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irKZ91MKyXQ2"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize SQLite database for storing updates\n",
        "def initialize_database():\n",
        "    conn = sqlite3.connect(\"legal_updates.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS updates (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            topic TEXT,\n",
        "            update_text TEXT,  -- Renamed 'update' to 'update_text'\n",
        "            timestamp DATETIME\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Function to save updates to the database\n",
        "def save_updates_to_db(conn, topic, updates):\n",
        "    cursor = conn.cursor()\n",
        "    timestamp = datetime.now()\n",
        "    for update in updates:\n",
        "        cursor.execute(\"INSERT INTO updates (topic, update_text, timestamp) VALUES (?, ?, ?)\", (topic, update, timestamp))\n",
        "    conn.commit()\n",
        "\n",
        "# Function to fetch previous updates from the database\n",
        "def fetch_previous_updates(conn, topic):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT update_text FROM updates WHERE topic = ? ORDER BY timestamp DESC\", (topic,))\n",
        "    return [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# Function to search for updates (mock for demo purposes)\n",
        "def search_for_updates(topic):\n",
        "    # Mocked updates: Replace with actual code to fetch updates via API or web scraping\n",
        "    if topic.lower() == \"criminal law\":\n",
        "        return [\n",
        "            \"New criminal law amendments passed in Parliament.\",\n",
        "            \"Supreme Court issues guidelines on criminal case hearings.\",\n",
        "        ]\n",
        "    elif topic.lower() == \"civil law\":\n",
        "        return [\n",
        "            \"Civil court fee structure revised.\",\n",
        "            \"Latest update on property disputes under civil law.\",\n",
        "        ]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Main function to handle the update search and fallback logic\n",
        "def search_updates(topic):\n",
        "    conn = initialize_database()\n",
        "\n",
        "    # Search for updates related to the topic\n",
        "    updates = search_for_updates(topic)\n",
        "\n",
        "    if updates:\n",
        "        # Save updates to the database\n",
        "        save_updates_to_db(conn, topic, updates)\n",
        "        print(f\"Latest updates for '{topic}':\")\n",
        "        for update in updates:\n",
        "            print(f\"- {update}\")\n",
        "    else:\n",
        "        # Fetch previous updates from the database if no new updates are found\n",
        "        previous_updates = fetch_previous_updates(conn, topic)\n",
        "        if previous_updates:\n",
        "            print(f\"No new updates found. Showing previous updates for '{topic}':\")\n",
        "            for update in previous_updates:\n",
        "                print(f\"- {update}\")\n",
        "        else:\n",
        "            print(f\"No updates found for the topic '{topic}'.\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    search_topic = input(\"Enter the topic you want to search updates for: \")\n",
        "    search_updates(search_topic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHIU_gU717nI"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize SQLite database for storing updates\n",
        "def initialize_database():\n",
        "    conn = sqlite3.connect(\"legal_updates.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS updates (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            topic TEXT,\n",
        "            update_text TEXT,\n",
        "            timestamp DATETIME\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Save updates to the database\n",
        "def save_updates_to_db(conn, topic, updates):\n",
        "    cursor = conn.cursor()\n",
        "    timestamp = datetime.now()\n",
        "    for update in updates:\n",
        "        cursor.execute(\"INSERT INTO updates (topic, update_text, timestamp) VALUES (?, ?, ?)\", (topic, update, timestamp))\n",
        "    conn.commit()\n",
        "\n",
        "# Fetch previous updates from the database\n",
        "def fetch_previous_updates(conn, topic):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT update_text FROM updates WHERE topic = ? ORDER BY timestamp DESC\", (topic,))\n",
        "    return [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# Function to scrape updates from LiveLaw\n",
        "def scrape_livelaw_updates(topic):\n",
        "    search_url = f\"https://www.livelaw.in/search?query={topic}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch data from LiveLaw. HTTP Status Code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    updates = []\n",
        "\n",
        "    # Parse news articles from LiveLaw\n",
        "    for article in soup.find_all(\"div\", class_=\"card-title\"):  # Adjust class name if LiveLaw changes its structure\n",
        "        title = article.text.strip()\n",
        "        updates.append(title)\n",
        "\n",
        "    return updates\n",
        "\n",
        "# Main function to handle update search and fallback logic\n",
        "def search_updates(topic):\n",
        "    conn = initialize_database()\n",
        "\n",
        "    # Fetch updates from LiveLaw\n",
        "    updates = scrape_livelaw_updates(topic)\n",
        "\n",
        "    if updates:\n",
        "        # Save updates to the database\n",
        "        save_updates_to_db(conn, topic, updates)\n",
        "        print(f\"Latest updates for '{topic}':\")\n",
        "        for update in updates:\n",
        "            print(f\"- {update}\")\n",
        "    else:\n",
        "        # Fetch previous updates if no new updates are found\n",
        "        previous_updates = fetch_previous_updates(conn, topic)\n",
        "        if previous_updates:\n",
        "            print(f\"No new updates found. Showing previous updates for '{topic}':\")\n",
        "            for update in previous_updates:\n",
        "                print(f\"- {update}\")\n",
        "        else:\n",
        "            print(f\"No updates found for the topic '{topic}'.\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    search_topic = input(\"Enter the topic you want to search updates for: \")\n",
        "    search_updates(search_topic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76IGV0Lsyqh0"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize SQLite database for storing updates\n",
        "def initialize_database():\n",
        "    conn = sqlite3.connect(\"legal_updates.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS updates (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            topic TEXT,\n",
        "            update_text TEXT,\n",
        "            timestamp DATETIME\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Save updates to the database\n",
        "def save_updates_to_db(conn, topic, updates):\n",
        "    cursor = conn.cursor()\n",
        "    timestamp = datetime.now()\n",
        "    for update in updates:\n",
        "        cursor.execute(\"INSERT INTO updates (topic, update_text, timestamp) VALUES (?, ?, ?)\", (topic, update, timestamp))\n",
        "    conn.commit()\n",
        "\n",
        "# Fetch previous updates from the database\n",
        "def fetch_previous_updates(conn, topic):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT update_text FROM updates WHERE topic = ? ORDER BY timestamp DESC\", (topic,))\n",
        "    return [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# Function to scrape updates from LiveLaw\n",
        "def scrape_livelaw_updates(topic):\n",
        "    search_url = f\"https://www.livelaw.in/search?query={topic.replace(' ', '+')}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch data from LiveLaw. HTTP Status Code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    updates = []\n",
        "\n",
        "    # Parse news articles from LiveLaw\n",
        "    for article in soup.find_all(\"div\", class_=\"card-title\"):  # Adjust class name if LiveLaw changes its structure\n",
        "        title = article.text.strip()\n",
        "        updates.append(title)\n",
        "\n",
        "    return updates\n",
        "\n",
        "# Main function to handle update search and fallback logic\n",
        "def search_updates(topic):\n",
        "    conn = initialize_database()\n",
        "\n",
        "    # Fetch updates from LiveLaw\n",
        "    updates = scrape_livelaw_updates(topic)\n",
        "\n",
        "    if updates:\n",
        "        # Save updates to the database\n",
        "        save_updates_to_db(conn, topic, updates)\n",
        "        print(f\"Latest updates for '{topic}':\")\n",
        "        for update in updates:\n",
        "            print(f\"- {update}\")\n",
        "    else:\n",
        "        # Fetch previous updates if no new updates are found\n",
        "        previous_updates = fetch_previous_updates(conn, topic)\n",
        "        if previous_updates:\n",
        "            print(f\"No new updates found. Showing previous updates for '{topic}':\")\n",
        "            for update in previous_updates:\n",
        "                print(f\"- {update}\")\n",
        "        else:\n",
        "            print(f\"No updates found for the topic '{topic}'.\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    search_topic = input(\"Enter the topic you want to search updates for: \")\n",
        "    search_updates(search_topic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Neu7lyX39gyI"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4 matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0od-V_D_zpgs"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize SQLite database for storing updates\n",
        "def initialize_database():\n",
        "    conn = sqlite3.connect(\"legal_updates.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS updates (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            topic TEXT,\n",
        "            update_text TEXT,\n",
        "            timestamp DATETIME\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Save updates to the database\n",
        "def save_updates_to_db(conn, topic, updates):\n",
        "    cursor = conn.cursor()\n",
        "    timestamp = datetime.now()\n",
        "    for update in updates:\n",
        "        cursor.execute(\"INSERT INTO updates (topic, update_text, timestamp) VALUES (?, ?, ?)\", (topic, update, timestamp))\n",
        "    conn.commit()\n",
        "\n",
        "# Fetch previous updates from the database\n",
        "def fetch_previous_updates(conn, topic):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT update_text FROM updates WHERE topic = ? ORDER BY timestamp DESC\", (topic,))\n",
        "    return [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# Function to scrape updates from LiveLaw\n",
        "def scrape_livelaw_updates(topic):\n",
        "    search_url = f\"https://www.livelaw.in/search?query={topic.replace(' ', '+')}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch data from LiveLaw. HTTP Status Code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    updates = []\n",
        "\n",
        "    # Parse news articles from LiveLaw\n",
        "    for article in soup.find_all(\"div\", class_=\"card-title\"):  # Adjust class name if LiveLaw changes its structure\n",
        "        title = article.text.strip()\n",
        "        updates.append(title)\n",
        "\n",
        "    return updates\n",
        "\n",
        "# Main function to handle update search and fallback logic\n",
        "def search_updates(topic):\n",
        "    conn = initialize_database()\n",
        "\n",
        "    # Fetch updates from LiveLaw\n",
        "    updates = scrape_livelaw_updates(topic)\n",
        "\n",
        "    if updates:\n",
        "        # Save updates to the database\n",
        "        save_updates_to_db(conn, topic, updates)\n",
        "        print(f\"Latest updates for '{topic}':\")\n",
        "        for update in updates:\n",
        "            print(f\"- {update}\")\n",
        "    else:\n",
        "        # Fetch previous updates if no new updates are found\n",
        "        previous_updates = fetch_previous_updates(conn, topic)\n",
        "        if previous_updates:\n",
        "            print(f\"No new updates found. Showing previous updates for '{topic}':\")\n",
        "            for update in previous_updates:\n",
        "                print(f\"- {update}\")\n",
        "        else:\n",
        "            print(f\"No updates found for the topic '{topic}'.\")\n",
        "\n",
        "    conn.close()\n",
        "    return updates\n",
        "\n",
        "# Visualize updates with Bar Graph, Pie Chart, and Heatmap\n",
        "def visualize_updates(updates, topic):\n",
        "    if updates:\n",
        "        update_counts = {topic: len(updates)}\n",
        "\n",
        "        # Bar Chart\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(update_counts.keys(), update_counts.values(), color=\"skyblue\")\n",
        "        plt.xlabel(\"Topics\", fontsize=12)\n",
        "        plt.ylabel(\"Number of Updates\", fontsize=12)\n",
        "        plt.title(f\"Number of Updates for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Pie Chart\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.pie(\n",
        "            update_counts.values(),\n",
        "            labels=update_counts.keys(),\n",
        "            autopct=\"%1.1f%%\",\n",
        "            startangle=140,\n",
        "            colors=[\"lightcoral\"]\n",
        "        )\n",
        "        plt.title(f\"Update Distribution for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Heatmap\n",
        "        data_matrix = [[len(updates)]]\n",
        "        sns.heatmap(data_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True, xticklabels=[topic], yticklabels=[\"Count\"])\n",
        "        plt.title(f\"Heatmap for Updates on '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No updates available to visualize for the topic '{topic}'.\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    search_topic = input(\"Enter the topic you want to search updates for: \")\n",
        "    updates = search_updates(search_topic)\n",
        "    visualize_updates(updates, search_topic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Om8rxw14eR7"
      },
      "outputs": [],
      "source": [
        "# Visualize updates with Bar Graph, Pie Chart, and Heatmap\n",
        "def visualize_updates(updates, topic):\n",
        "    if updates:\n",
        "        update_counts = {topic: len(updates)}\n",
        "\n",
        "        # Bar Chart\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(update_counts.keys(), update_counts.values(), color=\"skyblue\")\n",
        "        plt.xlabel(\"Topics\", fontsize=12)\n",
        "        plt.ylabel(\"Number of Updates\", fontsize=12)\n",
        "        plt.title(f\"Number of Updates for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Pie Chart\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.pie(\n",
        "            update_counts.values(),\n",
        "            labels=update_counts.keys(),\n",
        "            autopct=\"%1.1f%%\",\n",
        "            startangle=140,\n",
        "            colors=[\"lightcoral\"]\n",
        "        )\n",
        "        plt.title(f\"Update Distribution for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Heatmap\n",
        "        data_matrix = [[len(updates)]]\n",
        "        sns.heatmap(data_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True, xticklabels=[topic], yticklabels=[\"Count\"])\n",
        "        plt.title(f\"Heatmap for Updates on '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No updates available to visualize for the topic '{topic}'.\")\n",
        "        # Optional: Display a blank graph or placeholder message\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.text(0.5, 0.5, \"No Updates Available\", fontsize=16, ha='center', va='center', color=\"red\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"No Data to Visualize\", fontsize=14)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfI9i1Lu4eOb"
      },
      "outputs": [],
      "source": [
        "def search_updates(topic):\n",
        "    conn = initialize_database()\n",
        "\n",
        "    # Fetch updates from LiveLaw\n",
        "    updates = scrape_livelaw_updates(topic)\n",
        "\n",
        "    if updates:\n",
        "        # Save updates to the database\n",
        "        save_updates_to_db(conn, topic, updates)\n",
        "        print(f\"Latest updates for '{topic}':\")\n",
        "        for update in updates:\n",
        "            print(f\"- {update}\")\n",
        "    else:\n",
        "        # Fetch all updates if no updates are found for the specific topic\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT topic, update_text FROM updates ORDER BY timestamp DESC\")\n",
        "        all_updates = cursor.fetchall()\n",
        "        if all_updates:\n",
        "            print(f\"No new updates found for '{topic}'. Showing all available updates:\")\n",
        "            for update_topic, update_text in all_updates:\n",
        "                print(f\"- {update_topic}: {update_text}\")\n",
        "            # Combine all updates for visualization\n",
        "            updates = [f\"{update_topic}: {update_text}\" for update_topic, update_text in all_updates]\n",
        "        else:\n",
        "            print(f\"No updates found for the topic '{topic}'.\")\n",
        "\n",
        "    conn.close()\n",
        "    return updates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t1C2cDI4eLQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize SQLite database for storing updates\n",
        "def initialize_database():\n",
        "    conn = sqlite3.connect(\"legal_updates.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS updates (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            topic TEXT,\n",
        "            update_text TEXT,\n",
        "            timestamp DATETIME\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Save updates to the database\n",
        "def save_updates_to_db(conn, topic, updates):\n",
        "    cursor = conn.cursor()\n",
        "    timestamp = datetime.now()\n",
        "    for update in updates:\n",
        "        cursor.execute(\"INSERT INTO updates (topic, update_text, timestamp) VALUES (?, ?, ?)\", (topic, update, timestamp))\n",
        "    conn.commit()\n",
        "\n",
        "# Fetch previous updates from the database\n",
        "def fetch_previous_updates(conn, topic):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT update_text FROM updates WHERE topic = ? ORDER BY timestamp DESC\", (topic,))\n",
        "    return [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# Function to scrape updates from LiveLaw\n",
        "def scrape_livelaw_updates(topic):\n",
        "    search_url = f\"https://www.livelaw.in/search?query={topic.replace(' ', '+')}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch data from LiveLaw. HTTP Status Code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    updates = []\n",
        "\n",
        "    # Parse news articles from LiveLaw\n",
        "    for article in soup.find_all(\"div\", class_=\"card-title\"):  # Adjust class name if LiveLaw changes its structure\n",
        "        title = article.text.strip()\n",
        "        updates.append(title)\n",
        "\n",
        "    return updates\n",
        "\n",
        "# Main function to handle update search and fallback logic\n",
        "def search_updates(topic):\n",
        "    conn = initialize_database()\n",
        "\n",
        "    # Fetch updates from LiveLaw\n",
        "    updates = scrape_livelaw_updates(topic)\n",
        "\n",
        "    if updates:\n",
        "        # Save updates to the database\n",
        "        save_updates_to_db(conn, topic, updates)\n",
        "        print(f\"Latest updates for '{topic}':\")\n",
        "        for update in updates:\n",
        "            print(f\"- {update}\")\n",
        "    else:\n",
        "        # Fetch all updates if no updates are found for the specific topic\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT topic, update_text FROM updates ORDER BY timestamp DESC\")\n",
        "        all_updates = cursor.fetchall()\n",
        "        if all_updates:\n",
        "            print(f\"No new updates found for '{topic}'. Showing all available updates:\")\n",
        "            for update_topic, update_text in all_updates:\n",
        "                print(f\"- {update_topic}: {update_text}\")\n",
        "            # Combine all updates for visualization\n",
        "            updates = [f\"{update_topic}: {update_text}\" for update_topic, update_text in all_updates]\n",
        "        else:\n",
        "            print(f\"No updates found for the topic '{topic}'.\")\n",
        "\n",
        "    conn.close()\n",
        "    return updates\n",
        "\n",
        "# Visualize updates with Bar Graph, Pie Chart, and Heatmap\n",
        "def visualize_updates(updates, topic):\n",
        "    if updates:\n",
        "        update_counts = {topic: len(updates)}\n",
        "\n",
        "        # Bar Chart\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(update_counts.keys(), update_counts.values(), color=\"skyblue\")\n",
        "        plt.xlabel(\"Topics\", fontsize=12)\n",
        "        plt.ylabel(\"Number of Updates\", fontsize=12)\n",
        "        plt.title(f\"Number of Updates for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Pie Chart\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.pie(\n",
        "            update_counts.values(),\n",
        "            labels=update_counts.keys(),\n",
        "            autopct=\"%1.1f%%\",\n",
        "            startangle=140,\n",
        "            colors=[\"lightcoral\"]\n",
        "        )\n",
        "        plt.title(f\"Update Distribution for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Heatmap\n",
        "        data_matrix = [[len(updates)]]\n",
        "        sns.heatmap(data_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True, xticklabels=[topic], yticklabels=[\"Count\"])\n",
        "        plt.title(f\"Heatmap for Updates on '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No updates available to visualize for the topic '{topic}'.\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    search_topic = input(\"Enter the topic you want to search updates for: \")\n",
        "    updates = search_updates(search_topic)\n",
        "    visualize_updates(updates, search_topic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybzh-qWY4eJf"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize SQLite database for storing updates\n",
        "def initialize_database():\n",
        "    conn = sqlite3.connect(\"legal_updates.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS updates (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            topic TEXT,\n",
        "            update_text TEXT,\n",
        "            timestamp DATETIME\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Save updates to the database\n",
        "def save_updates_to_db(conn, topic, updates):\n",
        "    cursor = conn.cursor()\n",
        "    timestamp = datetime.now()\n",
        "    for update in updates:\n",
        "        cursor.execute(\"INSERT INTO updates (topic, update_text, timestamp) VALUES (?, ?, ?)\", (topic, update, timestamp))\n",
        "    conn.commit()\n",
        "\n",
        "# Fetch previous updates from the database\n",
        "def fetch_previous_updates(conn, topic):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT update_text FROM updates WHERE topic = ? ORDER BY timestamp DESC\", (topic,))\n",
        "    return [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# Function to scrape updates from LiveLaw\n",
        "def scrape_livelaw_updates(topic):\n",
        "    search_url = f\"https://www.livelaw.in/search?query={topic.replace(' ', '+')}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch data from LiveLaw. HTTP Status Code: {response.status_code}\")\n",
        "        return []\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    updates = []\n",
        "    for article in soup.find_all(\"div\", class_=\"card-title\"):  # Adjust class name if LiveLaw changes its structure\n",
        "        title = article.text.strip()\n",
        "        updates.append(title)\n",
        "    return updates\n",
        "\n",
        "# Function to scrape updates from another source (for example, Bar and Bench)\n",
        "def scrape_bar_and_bench_updates(topic):\n",
        "    search_url = f\"https://www.barandbench.com/search?q={topic.replace(' ', '+')}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch data from Bar and Bench. HTTP Status Code: {response.status_code}\")\n",
        "        return []\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    updates = []\n",
        "    for article in soup.find_all(\"h3\", class_=\"entry-title\"):  # Adjust class name if structure changes\n",
        "        title = article.text.strip()\n",
        "        updates.append(title)\n",
        "    return updates\n",
        "\n",
        "# Function to scrape updates from another source (for example, LiveMint)\n",
        "def scrape_livemint_updates(topic):\n",
        "    search_url = f\"https://www.livemint.com/search?q={topic.replace(' ', '+')}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch data from LiveMint. HTTP Status Code: {response.status_code}\")\n",
        "        return []\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    updates = []\n",
        "    for article in soup.find_all(\"a\", class_=\"headline\"):  # Adjust class name if structure changes\n",
        "        title = article.text.strip()\n",
        "        updates.append(title)\n",
        "    return updates\n",
        "\n",
        "# Main function to handle update search and fallback logic\n",
        "def search_updates(topic):\n",
        "    conn = initialize_database()\n",
        "\n",
        "    # First try fetching updates from LiveLaw\n",
        "    updates = scrape_livelaw_updates(topic)\n",
        "\n",
        "    # If LiveLaw doesn't provide sufficient updates, try other sources\n",
        "    if not updates or len(updates) < 1:  # Check for insufficient updates\n",
        "        print(f\"No updates found on LiveLaw. Trying fallback sources...\")\n",
        "\n",
        "        # Try Bar and Bench if LiveLaw didn't provide updates\n",
        "        updates = scrape_bar_and_bench_updates(topic)\n",
        "\n",
        "    if not updates or len(updates) < 1:  # Check if still no updates\n",
        "        print(f\"No updates found on Bar and Bench. Trying LiveMint...\")\n",
        "\n",
        "        # Try LiveMint if Bar and Bench also didn't provide updates\n",
        "        updates = scrape_livemint_updates(topic)\n",
        "\n",
        "    if updates:\n",
        "        # Save updates to the database\n",
        "        save_updates_to_db(conn, topic, updates)\n",
        "        print(f\"Latest updates for '{topic}':\")\n",
        "        for update in updates:\n",
        "            print(f\"- {update}\")\n",
        "    else:\n",
        "        # Fetch all updates if no updates are found for the specific topic\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT topic, update_text FROM updates ORDER BY timestamp DESC\")\n",
        "        all_updates = cursor.fetchall()\n",
        "        if all_updates:\n",
        "            print(f\"No new updates found for '{topic}'. Showing all available updates:\")\n",
        "            for update_topic, update_text in all_updates:\n",
        "                print(f\"- {update_topic}: {update_text}\")\n",
        "            # Combine all updates for visualization\n",
        "            updates = [f\"{update_topic}: {update_text}\" for update_topic, update_text in all_updates]\n",
        "        else:\n",
        "            print(f\"No updates found for the topic '{topic}'.\")\n",
        "\n",
        "    conn.close()\n",
        "    return updates\n",
        "\n",
        "# Visualize updates with Bar Graph, Pie Chart, and Heatmap\n",
        "def visualize_updates(updates, topic):\n",
        "    if updates:\n",
        "        update_counts = {topic: len(updates)}\n",
        "\n",
        "        # Bar Chart\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(update_counts.keys(), update_counts.values(), color=\"skyblue\")\n",
        "        plt.xlabel(\"Topics\", fontsize=12)\n",
        "        plt.ylabel(\"Number of Updates\", fontsize=12)\n",
        "        plt.title(f\"Number of Updates for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Pie Chart\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.pie(\n",
        "            update_counts.values(),\n",
        "            labels=update_counts.keys(),\n",
        "            autopct=\"%1.1f%%\",\n",
        "            startangle=140,\n",
        "            colors=[\"lightcoral\"]\n",
        "        )\n",
        "        plt.title(f\"Update Distribution for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Heatmap (Handle multiple topics)\n",
        "        if len(updates) > 1:\n",
        "            data_matrix = [[len(updates)] for _ in range(len(updates))]\n",
        "            sns.heatmap(data_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True, xticklabels=[topic] * len(updates), yticklabels=[f\"Update {i+1}\" for i in range(len(updates))])\n",
        "        else:\n",
        "            sns.heatmap([[len(updates)]], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True, xticklabels=[topic], yticklabels=[\"Count\"])\n",
        "        plt.title(f\"Heatmap for Updates on '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No updates available to visualize for the topic '{topic}'.\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    search_topic = input(\"Enter the topic you want to search updates for: \")\n",
        "    updates = search_updates(search_topic)\n",
        "    visualize_updates(updates, search_topic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OPlOBf34eHH"
      },
      "outputs": [],
      "source": [
        "!pip install gradio speechrecognition gtts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvAMsH31aSq7"
      },
      "outputs": [],
      "source": [
        "# Visualize updates with Bar Graph, Pie Chart, and Heatmap\n",
        "def visualize_updates(updates, topic):\n",
        "    if updates:\n",
        "        update_counts = {topic: len(updates)}\n",
        "\n",
        "        # Bar Chart\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.bar(update_counts.keys(), update_counts.values(), color=\"skyblue\")\n",
        "        plt.xlabel(\"Topics\", fontsize=12)\n",
        "        plt.ylabel(\"Number of Updates\", fontsize=12)\n",
        "        plt.title(f\"Number of Updates for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Pie Chart\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.pie(\n",
        "            update_counts.values(),\n",
        "            labels=update_counts.keys(),\n",
        "            autopct=\"%1.1f%%\",\n",
        "            startangle=140,\n",
        "            colors=[\"lightcoral\"]\n",
        "        )\n",
        "        plt.title(f\"Update Distribution for '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Heatmap\n",
        "        data_matrix = [[len(updates)]]\n",
        "        sns.heatmap(data_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True, xticklabels=[topic], yticklabels=[\"Count\"])\n",
        "        plt.title(f\"Heatmap for Updates on '{topic}'\", fontsize=14)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No updates available to visualize for the topic '{topic}'.\")\n",
        "        # Optional: Display a blank graph or placeholder message\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.text(0.5, 0.5, \"No Updates Available\", fontsize=16, ha='center', va='center', color=\"red\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"No Data to Visualize\", fontsize=14)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "240JHgPd_DA4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gYP6B27smjU"
      },
      "outputs": [],
      "source": [
        "!pip install torchaudio transformers gradio librosa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VBKzUthsmf1"
      },
      "outputs": [],
      "source": [
        "import os                                                  #audio as transcribed text q and a\n",
        "import librosa\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained models\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Function to transcribe audio using Wav2Vec2\n",
        "def transcribe_audio(file_path):\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to process audio dataset\n",
        "def process_audio_query(audio_file, context):\n",
        "    transcription = transcribe_audio(audio_file)  # Speech-to-text\n",
        "    answer = qa_pipeline(question=transcription, context=context)  # Generate answer\n",
        "    return transcription, answer[\"answer\"]\n",
        "\n",
        "# Context for legal queries\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Gradio Interface for Audio Dataset Integration\n",
        "import gradio as gr\n",
        "\n",
        "def handle_audio_query(audio_file):\n",
        "    transcription, answer = process_audio_query(audio_file, legal_context)\n",
        "    return transcription, answer\n",
        "\n",
        "with gr.Interface(\n",
        "    fn=handle_audio_query,\n",
        "    inputs=gr.Audio(type=\"filepath\", label=\"Upload your audio query:\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Transcribed Question\"),\n",
        "        gr.Textbox(label=\"Answer\"),\n",
        "    ],\n",
        "    title=\"Smart Legal Navigator - Audio Integration\"\n",
        ") as demo:\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEiqPEwkuuPJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26mpvnJxwR6n"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/audio_dataset (1).zip\"  # Path to your zip file\n",
        "extract_path = \"/content/audio_dataset\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Dataset extracted to:\", extract_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIU17XWQwgnj"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/audio_dataset (1).zip\"  # Path to the uploaded zip file\n",
        "extract_path = \"/content/audio_dataset\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Dataset extracted to:\", extract_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M849UBxauubx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "\n",
        "audio_dir = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/extracted_audio\"\n",
        "transcript_dir = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/extracted_audio\"\n",
        "\n",
        "# List audio files\n",
        "audio_files = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
        "transcript_files = [os.path.join(transcript_dir, f) for f in os.listdir(transcript_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "# Ensure alignment of audio and transcript files\n",
        "dataset = []\n",
        "for audio_path, transcript_path in zip(audio_files, transcript_files):\n",
        "    with open(transcript_path, \"r\") as f:\n",
        "        transcript = f.read().strip()\n",
        "    dataset.append((audio_path, transcript))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2_GGEYBwx0P"
      },
      "outputs": [],
      "source": [
        "                                                      #Final Audio with transcribed question# Install necessary libraries\n",
        "!pip install gradio transformers librosa gtts torch\n",
        "import os\n",
        "import librosa\n",
        "import torch\n",
        "from gtts import gTTS\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# Load the pre-trained Wav2Vec2 model for ASR (speech-to-text)\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load the pre-trained QA pipeline\n",
        "print(\"Loading Question Answering model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Legal context for the chatbot\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to handle audio queries\n",
        "def process_audio_query(audio_file, context):\n",
        "    # Transcribe the audio\n",
        "    transcription = transcribe_audio(audio_file)\n",
        "\n",
        "    # Generate the answer\n",
        "    answer = qa_pipeline(question=transcription, context=context)[\"answer\"]\n",
        "\n",
        "    # Convert the answer to speech\n",
        "    tts = gTTS(answer)\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return transcription, answer, tts_audio_path\n",
        "\n",
        "# Gradio Interface for the Smart Legal Navigator Chatbot\n",
        "def handle_audio_query(audio_file):\n",
        "    transcription, answer, tts_audio_path = process_audio_query(audio_file, legal_context)\n",
        "    return transcription, answer, tts_audio_path\n",
        "\n",
        "# Create Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Smart Legal Navigator - Audio Interaction\")\n",
        "\n",
        "    # Audio Query Input\n",
        "    audio_input = gr.Audio(type=\"filepath\", label=\"Upload your audio question:\")\n",
        "    transcription_output = gr.Textbox(label=\"Transcribed Question\", interactive=False)\n",
        "    text_answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "    audio_output = gr.Audio(label=\"Answer (Audio)\")\n",
        "\n",
        "    # Button to trigger processing\n",
        "    submit_button = gr.Button(\"Get Answer\")\n",
        "    submit_button.click(\n",
        "        fn=handle_audio_query,\n",
        "        inputs=[audio_input],\n",
        "        outputs=[transcription_output, text_answer_output, audio_output]\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCvCKqXn_C9c"
      },
      "outputs": [],
      "source": [
        "pip install googletrans==4.0.0-rc1 gradio transformers librosa gtts torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lrKT1HqalTT"
      },
      "outputs": [],
      "source": [
        "import os                                                  #audio as transcribed text q and a\n",
        "import librosa\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained models\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Function to transcribe audio using Wav2Vec2\n",
        "def transcribe_audio(file_path):\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to process audio dataset\n",
        "def process_audio_query(audio_file, context):\n",
        "    transcription = transcribe_audio(audio_file)  # Speech-to-text\n",
        "    answer = qa_pipeline(question=transcription, context=context)  # Generate answer\n",
        "    return transcription, answer[\"answer\"]\n",
        "\n",
        "# Context for legal queries\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Gradio Interface for Audio Dataset Integration\n",
        "import gradio as gr\n",
        "\n",
        "def handle_audio_query(audio_file):\n",
        "    transcription, answer = process_audio_query(audio_file, legal_context)\n",
        "    return transcription, answer\n",
        "\n",
        "with gr.Interface(\n",
        "    fn=handle_audio_query,\n",
        "    inputs=gr.Audio(type=\"filepath\", label=\"Upload your audio query:\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Transcribed Question\"),\n",
        "        gr.Textbox(label=\"Answer\"),\n",
        "    ],\n",
        "    title=\"Smart Legal Navigator - Audio Integration\"\n",
        ") as demo:\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a3bydLFalIe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0NTHjzW_j4i"
      },
      "outputs": [],
      "source": [
        "# Import libraries              error with translator able to upload audio not translator\n",
        "import os\n",
        "import librosa\n",
        "import torch\n",
        "from gtts import gTTS\n",
        "from googletrans import Translator\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# Initialize Google Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load the pre-trained Wav2Vec2 model for ASR (speech-to-text)\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load the pre-trained QA pipeline\n",
        "print(\"Loading Question Answering model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Legal context for the chatbot\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to handle audio queries with translation\n",
        "def process_audio_query(audio_file, target_language):\n",
        "    # Transcribe the audio\n",
        "    transcription = transcribe_audio(audio_file)\n",
        "\n",
        "    # Translate transcription to English if needed\n",
        "    if target_language != \"en\":\n",
        "        transcription = translator.translate(transcription, src=target_language, dest=\"en\").text\n",
        "\n",
        "    # Generate the answer\n",
        "    answer = qa_pipeline(question=transcription, context=legal_context)[\"answer\"]\n",
        "\n",
        "    # Translate the answer to the target language if needed\n",
        "    if target_language != \"en\":\n",
        "        answer = translator.translate(answer, src=\"en\", dest=target_language).text\n",
        "\n",
        "    # Convert the answer to speech\n",
        "    tts = gTTS(answer, lang=target_language)\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return transcription, answer, tts_audio_path\n",
        "\n",
        "# Gradio Interface for the Smart Legal Navigator Chatbot\n",
        "def handle_audio_query(audio_file, target_language):\n",
        "    transcription, answer, tts_audio_path = process_audio_query(audio_file, target_language)\n",
        "    return transcription, answer, tts_audio_path\n",
        "\n",
        "# Create Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Smart Legal Navigator - Audio Interaction with Translation Support (Google Translator)\")\n",
        "\n",
        "    # Audio Query Input\n",
        "    audio_input = gr.Audio(type=\"filepath\", label=\"Upload your audio question:\")\n",
        "    language_selector = gr.Dropdown(\n",
        "        choices=[\"en\", \"hi\", \"ta\", \"te\", \"bn\", \"kn\", \"ml\", \"gu\", \"mr\", \"pa\", \"ur\"],\n",
        "        value=\"en\",\n",
        "        label=\"Select Language (default: English)\",\n",
        "    )\n",
        "    transcription_output = gr.Textbox(label=\"Transcribed Question\", interactive=False)\n",
        "    text_answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "    audio_output = gr.Audio(label=\"Answer (Audio)\")\n",
        "\n",
        "    # Button to trigger processing\n",
        "    submit_button = gr.Button(\"Get Answer\")\n",
        "    submit_button.click(\n",
        "        fn=handle_audio_query,\n",
        "        inputs=[audio_input, language_selector],\n",
        "        outputs=[transcription_output, text_answer_output, audio_output]\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJCl8WIZCh1I"
      },
      "outputs": [],
      "source": [
        "!pip install azure-ai-translation\n",
        "!pip install azure-identity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx9JUz53CNIj"
      },
      "outputs": [],
      "source": [
        "!pip install gradio librosa torch transformers gtts googletrans==4.0.0-rc1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv02hXgRCNE-"
      },
      "outputs": [],
      "source": [
        "# Import libraries                       shows error\n",
        "import os\n",
        "import torch\n",
        "from gtts import gTTS\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "import gradio as gr\n",
        "import librosa\n",
        "\n",
        "# Initialize Wav2Vec2 ASR model\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load the pre-trained QA pipeline\n",
        "print(\"Loading Question Answering model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Legal context for the chatbot\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to process the query\n",
        "def process_query(query):\n",
        "    # Generate the answer using the context\n",
        "    answer = qa_pipeline(question=query, context=legal_context)[\"answer\"]\n",
        "\n",
        "    # Convert the answer to speech\n",
        "    tts = gTTS(answer, lang=\"en\")\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return query, answer, tts_audio_path\n",
        "\n",
        "# Gradio Interface for Text and Audio Input\n",
        "def handle_query(audio_file, text_input):\n",
        "    if audio_file:\n",
        "        # Process audio input\n",
        "        transcription = transcribe_audio(audio_file)\n",
        "        query, answer, tts_audio_path = process_query(transcription)\n",
        "    elif text_input:\n",
        "        # Process text input\n",
        "        query, answer, tts_audio_path = process_query(text_input)\n",
        "    else:\n",
        "        return \"No input provided\", \"\", None\n",
        "\n",
        "    return query, answer, tts_audio_path\n",
        "\n",
        "# Create Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Smart Legal Navigator\")\n",
        "\n",
        "    # Inputs\n",
        "    with gr.Row():\n",
        "        audio_input = gr.Audio(type=\"filepath\", label=\"Upload your audio question:\")\n",
        "        text_input = gr.Textbox(label=\"Or type your text question:\")\n",
        "\n",
        "    # Outputs\n",
        "    transcription_output = gr.Textbox(label=\"Processed Question\", interactive=False)\n",
        "    text_answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "    audio_output = gr.Audio(label=\"Answer (Audio)\")\n",
        "\n",
        "    # Button to trigger processing\n",
        "    submit_button = gr.Button(\"Get Answer\")\n",
        "    submit_button.click(\n",
        "        fn=handle_query,\n",
        "        inputs=[audio_input, text_input],\n",
        "        outputs=[transcription_output, text_answer_output, audio_output]\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZqQhQe6KKiL"
      },
      "outputs": [],
      "source": [
        "!pip install torch librosa gtts transformers streamlit pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRGkVyy4LArj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZoOABzRKKes"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zRN63d7KKcc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "from gtts import gTTS\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "\n",
        "# Load Wav2Vec2 ASR model\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load Question Answering model\n",
        "print(\"Loading Question Answering model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Legal context for the chatbot\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    print(f\"Processing audio file: {file_path}\")\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to process the query\n",
        "def process_query(query):\n",
        "    # Generate the answer using the legal context\n",
        "    answer = qa_pipeline(question=query, context=legal_context)[\"answer\"]\n",
        "\n",
        "    # Convert the answer to speech\n",
        "    tts = gTTS(answer, lang=\"en\")\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return query, answer, tts_audio_path\n",
        "\n",
        "# Main Program Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Smart Legal Navigator CLI!\")\n",
        "    print(\"You can ask a question via text or provide an audio file.\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nChoose an option:\")\n",
        "        print(\"1. Enter a text question\")\n",
        "        print(\"2. Upload an audio file (WAV/MP3)\")\n",
        "        print(\"3. Exit\")\n",
        "        choice = input(\"Enter your choice (1/2/3): \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            # Text input\n",
        "            text_input = input(\"Enter your question: \")\n",
        "            query, answer, tts_audio_path = process_query(text_input)\n",
        "            print(f\"Question: {query}\")\n",
        "            print(f\"Answer: {answer}\")\n",
        "            print(f\"Audio answer saved at: {tts_audio_path}\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            # Audio input\n",
        "            audio_path = input(\"Enter the path to your audio file: \")\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(\"Invalid file path. Please try again.\")\n",
        "                continue\n",
        "            transcription = transcribe_audio(audio_path)\n",
        "            print(f\"Transcribed Question: {transcription}\")\n",
        "            query, answer, tts_audio_path = process_query(transcription)\n",
        "            print(f\"Answer: {answer}\")\n",
        "            print(f\"Audio answer saved at: {tts_audio_path}\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            print(\"Exiting the application. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaRWW2TJrgQD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "from gtts import gTTS\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "import json\n",
        "\n",
        "# Load Wav2Vec2 ASR model\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load Question Answering model\n",
        "print(\"Loading Question Answering model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Load the legal dataset\n",
        "print(\"Loading legal dataset...\")\n",
        "dataset_file = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/updated_ipc_qa.json\"  # Replace with your dataset file path\n",
        "if os.path.exists(dataset_file):\n",
        "    with open(dataset_file, 'r') as f:\n",
        "        legal_dataset = json.load(f)\n",
        "else:\n",
        "    print(f\"Dataset file '{dataset_file}' not found.\")\n",
        "    legal_dataset = []\n",
        "\n",
        "# Function to find the most relevant context for a query\n",
        "def find_relevant_context(query):\n",
        "    # Search for the best matching context from the dataset\n",
        "    for entry in legal_dataset:\n",
        "        if query.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return \"Sorry, I couldn't find an answer to your question in the dataset.\"\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    print(f\"Processing audio file: {'/content/reduced_combined_qa.json'}\")\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to process the query\n",
        "def process_query(query):\n",
        "    # Find the answer in the dataset\n",
        "    answer = find_relevant_context(query)\n",
        "\n",
        "    # Convert the answer to speech\n",
        "    tts = gTTS(answer, lang=\"en\")\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return query, answer, tts_audio_path\n",
        "\n",
        "# Main Program Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Smart Legal Navigator CLI!\")\n",
        "    print(\"You can ask a question via text or provide an audio file.\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nChoose an option:\")\n",
        "        print(\"1. Enter a text question\")\n",
        "        print(\"2. Upload an audio file (WAV/MP3)\")\n",
        "        print(\"3. Exit\")\n",
        "        choice = input(\"Enter your choice (1/2/3): \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            # Text input\n",
        "            text_input = input(\"Enter your question: \")\n",
        "            query, answer, tts_audio_path = process_query(text_input)\n",
        "            print(f\"Question: {query}\")\n",
        "            print(f\"Answer: {answer}\")\n",
        "            print(f\"Audio answer saved at: {tts_audio_path}\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            # Audio input\n",
        "            audio_path = input(\"Enter the path to your audio file: \")\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(\"Invalid file path. Please try again.\")\n",
        "                continue\n",
        "            transcription = transcribe_audio(audio_path)\n",
        "            print(f\"Transcribed Question: {transcription}\")\n",
        "            query, answer, tts_audio_path = process_query(transcription)\n",
        "            print(f\"Answer: {answer}\")\n",
        "            print(f\"Audio answer saved at: {tts_audio_path}\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            print(\"Exiting the application. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6U1KrtR_rxW"
      },
      "outputs": [],
      "source": [
        "pip install googletrans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKHiBD1oKKZ4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "from gtts import gTTS\n",
        "from googletrans import Translator\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "\n",
        "# Initialize Google Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load Wav2Vec2 ASR model\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load Question Answering model\n",
        "print(\"Loading Question Answering model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Legal context for the chatbot\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    print(f\"Processing audio file: {file_path}\")\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to translate text using Google Translator\n",
        "def translate_text(query, src_lang, target_lang):\n",
        "    translated_text = translator.translate(query, src=src_lang, dest=target_lang).text\n",
        "    return translated_text\n",
        "\n",
        "# Function to process the query\n",
        "def process_query(query, src_language, target_language):\n",
        "    # Translate query to English if it's not in English\n",
        "    if src_language != \"en\":\n",
        "        query = translate_text(query, src_lang=src_language, target_lang=\"en\")\n",
        "\n",
        "    # Generate the answer using the legal context\n",
        "    answer = qa_pipeline(question=query, context=legal_context)[\"answer\"]\n",
        "\n",
        "    # Translate the answer back to the target language if needed\n",
        "    if target_language != \"en\":\n",
        "        answer = translate_text(answer, src_lang=\"en\", target_lang=target_language)\n",
        "\n",
        "    # Convert the answer to speech in the target language\n",
        "    tts = gTTS(answer, lang=target_language)\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return query, answer, tts_audio_path\n",
        "\n",
        "# Main Program Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Multilingual Smart Legal Navigator CLI!\")\n",
        "    print(\"You can ask a question via text or provide an audio file.\")\n",
        "    print(\"Supported Languages: English (en), Hindi (hi), Tamil (ta), Telugu (te), Bengali (bn), Kannada (kn), Malayalam (ml), Gujarati (gu), Marathi (mr), Punjabi (pa), Urdu (ur)\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nChoose an option:\")\n",
        "        print(\"1. Enter a text question\")\n",
        "        print(\"2. Upload an audio file (WAV/MP3)\")\n",
        "        print(\"3. Exit\")\n",
        "        choice = input(\"Enter your choice (1/2/3): \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            # Text input\n",
        "            text_input = input(\"Enter your question: \")\n",
        "            src_lang = input(\"Enter the language of your question (e.g., en, hi, ta): \").strip()\n",
        "            target_lang = input(\"Enter the language for the answer (e.g., en, hi, ta): \").strip()\n",
        "\n",
        "            query, answer, tts_audio_path = process_query(text_input, src_lang, target_lang)\n",
        "            print(f\"Processed Question (English): {query}\")\n",
        "            print(f\"Answer ({target_lang}): {answer}\")\n",
        "            print(f\"Audio answer saved at: {tts_audio_path}\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            # Audio input\n",
        "            audio_path = input(\"Enter the path to your audio file: \")\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(\"Invalid file path. Please try again.\")\n",
        "                continue\n",
        "            transcription = transcribe_audio(audio_path)\n",
        "            print(f\"Transcribed Question: {transcription}\")\n",
        "\n",
        "            src_lang = input(\"Enter the language of your question (e.g., en, hi, ta): \").strip()\n",
        "            target_lang = input(\"Enter the language for the answer (e.g., en, hi, ta): \").strip()\n",
        "\n",
        "            query, answer, tts_audio_path = process_query(transcription, src_lang, target_lang)\n",
        "            print(f\"Answer ({target_lang}): {answer}\")\n",
        "            print(f\"Audio answer saved at: {tts_audio_path}\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            print(\"Exiting the application. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvnBCwV_T6Y8"
      },
      "outputs": [],
      "source": [
        "pip install gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoWLKdbYUBOq"
      },
      "outputs": [],
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9R2mO4iWFvC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "dataset_file = \"reduced_legal_qa.json\"\n",
        "\n",
        "with open(dataset_file, 'r', encoding=\"utf-8\") as f:\n",
        "    try:\n",
        "        legal_dataset = json.load(f)\n",
        "        print(\"JSON file loaded successfully!\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON Decode Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pJcK_28vAPR"
      },
      "outputs": [],
      "source": [
        "import os                      #CLI with translator\n",
        "import json  # Importing json module\n",
        "import torch\n",
        "import librosa\n",
        "from gtts import gTTS\n",
        "from googletrans import Translator\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "\n",
        "# Initialize Google Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load Wav2Vec2 ASR model\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading legal dataset...\")\n",
        "dataset_file = \"/content/reduced_legal_qa.json\"  # Replace with your dataset file path\n",
        "if os.path.exists(dataset_file):\n",
        "    with open('/content/reduced_legal_qa.json', 'r') as f:\n",
        "        legal_dataset = json.load(f)\n",
        "else:\n",
        "    print(f\"Dataset file '{dataset_file}' not found.\")\n",
        "    legal_dataset = []\n",
        "\n",
        "# Function to find the most relevant context from the dataset\n",
        "def find_relevant_context(query):\n",
        "    for entry in legal_dataset:\n",
        "        if query.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return \"Sorry, I couldn't find an answer to your question in the dataset.\"\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    print(f\"Processing audio file: {file_path}\")\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to translate text using Google Translator\n",
        "def translate_text(query, src_lang, target_lang):\n",
        "    translated_text = translator.translate(query, src=src_lang, dest=target_lang).text\n",
        "    return translated_text\n",
        "\n",
        "# Function to process the query\n",
        "def process_query(query, src_language, target_language):\n",
        "    # Translate query to English if it's not in English\n",
        "    if src_language != \"en\":\n",
        "        query = translate_text(query, src_lang=src_language, target_lang=\"en\")\n",
        "\n",
        "    # Find the answer in the dataset\n",
        "    answer = find_relevant_context(query)\n",
        "\n",
        "    # Translate the answer back to the target language if needed\n",
        "    if target_language != \"en\":\n",
        "        answer = translate_text(answer, src_lang=\"en\", target_lang=target_language)\n",
        "\n",
        "    # Convert the answer to speech in the target language\n",
        "    tts = gTTS(answer, lang=target_language)\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return query, answer, tts_audio_path\n",
        "\n",
        "# Main Program Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Multilingual Smart Legal Navigator CLI!\")\n",
        "    print(\"You can ask a question via text or provide an audio file.\")\n",
        "    print(\"Supported Languages: English (en), Hindi (hi), Tamil (ta), Telugu (te), Bengali (bn), Kannada (kn), Malayalam (ml), Gujarati (gu), Marathi (mr), Punjabi (pa), Urdu (ur)\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nChoose an option:\")\n",
        "        print(\"1. Enter a text question\")\n",
        "        print(\"2. Upload an audio file (WAV/MP3)\")\n",
        "        print(\"3. Exit\")\n",
        "        choice = input(\"Enter your choice (1/2/3): \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            # Text input\n",
        "            text_input = input(\"Enter your question: \")\n",
        "            src_lang = input(\"Enter the language of your question (e.g., en, hi, ta): \").strip()\n",
        "            target_lang = input(\"Enter the language for the answer (e.g., en, hi, ta): \").strip()\n",
        "\n",
        "            query, answer, tts_audio_path = process_query(text_input, src_lang, target_lang)\n",
        "            print(f\"Processed Question (English): {query}\")\n",
        "            print(f\"Answer ({target_lang}): {answer}\")\n",
        "            print(f\"Audio answer saved at: {tts_audio_path}\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            # Audio input\n",
        "            audio_path = input(\"Enter the path to your audio file: \")\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(\"Invalid file path. Please try again.\")\n",
        "                continue\n",
        "            transcription = transcribe_audio(audio_path)\n",
        "            print(f\"Transcribed Question: {transcription}\")\n",
        "\n",
        "            src_lang = input(\"Enter the language of your question (e.g., en, hi, ta): \").strip()\n",
        "            target_lang = input(\"Enter the language for the answer (e.g., en, hi, ta): \").strip()\n",
        "\n",
        "            query, answer, tts_audio_path = process_query(transcription, src_lang, target_lang)\n",
        "            print(f\"Answer ({target_lang}): {answer}\")\n",
        "            print(f\"Audio answer saved at: {tts_audio_path}\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            print(\"Exiting the application. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhTpiZ4-Bprz"
      },
      "outputs": [],
      "source": [
        "pip install gtts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq0bdvgDTwrw"
      },
      "outputs": [],
      "source": [
        "!pip install googletrans==4.0.0-rc1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGBlyO0-EdEC"
      },
      "outputs": [],
      "source": [
        "# translator with all languages text to audio output\n",
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "from gtts import gTTS\n",
        "from googletrans import Translator\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from IPython.display import Audio, display\n",
        "import json\n",
        "\n",
        "# Initialize translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load Wav2Vec2 ASR model\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading legal dataset...\")\n",
        "dataset_file = \"/content/crpc_qa.json\"  # Replace with your dataset file path\n",
        "if os.path.exists(dataset_file):\n",
        "    with open(dataset_file, 'r') as f:\n",
        "        legal_dataset = json.load(f)\n",
        "else:\n",
        "    print(f\"Dataset file '{dataset_file}' not found.\")\n",
        "    legal_dataset = []\n",
        "\n",
        "# Function to find the most relevant answer from the dataset\n",
        "def find_relevant_context(query):\n",
        "    for entry in legal_dataset:\n",
        "        if query.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return None  # Return None if no match is found\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to translate text\n",
        "def translate_text(query, src_lang, target_lang):\n",
        "    translated_text = translator.translate(query, src=src_lang, dest=target_lang).text\n",
        "    return translated_text\n",
        "\n",
        "# Function to process the query\n",
        "def process_query(query, src_language, target_language):\n",
        "    # Translate query to English if needed\n",
        "    if src_language != \"en\":\n",
        "        query = translate_text(query, src_language, \"en\")\n",
        "\n",
        "    # Try to find an answer in the dataset\n",
        "    answer = find_relevant_context(query)\n",
        "    if not answer:  # If no answer is found in the dataset, use the fallback context\n",
        "        answer = \"Sorry, I couldn't find an exact match for your question.\"\n",
        "\n",
        "    # Translate the answer to target language if needed\n",
        "    if target_language != \"en\":\n",
        "        answer = translate_text(answer, \"en\", target_language)\n",
        "\n",
        "    # Generate TTS for the answer\n",
        "    tts = gTTS(answer, lang=target_language)\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return query, answer, tts_audio_path\n",
        "\n",
        "# Simulated Colab User Interaction\n",
        "def run_in_colab():\n",
        "    # User inputs\n",
        "    print(\"Enter your question or type 'audio' to upload an audio file:\")\n",
        "    user_input = input(\"Your input: \")\n",
        "\n",
        "    if user_input.lower() == \"audio\":\n",
        "        # Upload audio\n",
        "        from google.colab import files\n",
        "        print(\"Upload your audio file (wav/mp3):\")\n",
        "        uploaded = files.upload()\n",
        "        audio_path = next(iter(uploaded.keys()))\n",
        "        query = transcribe_audio(audio_path)\n",
        "        print(f\"Transcribed Question: {query}\")\n",
        "    else:\n",
        "        query = user_input\n",
        "\n",
        "    # Language selection\n",
        "    src_lang = input(\"Enter source language (e.g., en, hi, ta, etc.): \").strip() or \"en\"\n",
        "    target_lang = input(\"Enter target language (e.g., en, hi, ta, etc.): \").strip() or \"en\"\n",
        "\n",
        "\n",
        "    print(\"Processing your query...\")\n",
        "    processed_query, answer, tts_audio_path = process_query(query, src_lang, target_lang)\n",
        "\n",
        "    print(f\"\\nProcessed Question: {processed_query}\")\n",
        "    print(f\"Answer: {answer}\")\n",
        "\n",
        "\n",
        "    print(\"\\nPlaying audio response:\")\n",
        "    display(Audio(tts_audio_path, autoplay=True))\n",
        "\n",
        "\n",
        "run_in_colab()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R-InncfR5Gg"
      },
      "outputs": [],
      "source": [
        "!pip install flask flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5ntcPhmEJaf"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install flask-ngrok torch librosa gtts googletrans==4.0.0-rc1 transformers\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "from gtts import gTTS\n",
        "from googletrans import Translator\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# Initialize Flask App\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # For Colab compatibility\n",
        "\n",
        "# Initialize translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load Wav2Vec2 ASR model\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load Question Answering model\n",
        "print(\"Loading Question Answering model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Legal context\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Transcribe audio to text\n",
        "def transcribe_audio(file_path):\n",
        "    audio, rate = librosa.load(file_path, sr=16000)  # Ensure 16kHz sampling rate\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Translate text\n",
        "def translate_text(query, src_lang, target_lang):\n",
        "    return translator.translate(query, src=src_lang, dest=target_lang).text\n",
        "\n",
        "# Process query\n",
        "def process_query(query, src_language, target_language):\n",
        "    # Translate query to English if needed\n",
        "    if src_language != \"en\":\n",
        "        query = translate_text(query, src_language, \"en\")\n",
        "\n",
        "    # Generate the answer\n",
        "    answer = qa_pipeline(question=query, context=legal_context)[\"answer\"]\n",
        "\n",
        "    # Translate the answer to target language if needed\n",
        "    if target_language != \"en\":\n",
        "        answer = translate_text(answer, \"en\", target_language)\n",
        "\n",
        "    # Generate TTS for the answer\n",
        "    tts = gTTS(answer, lang=target_language)\n",
        "    tts_audio_path = \"response.mp3\"\n",
        "    tts.save(tts_audio_path)\n",
        "\n",
        "    return query, answer, tts_audio_path\n",
        "\n",
        "# Flask routes\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return \"Smart Legal Navigator Backend is Running!\"\n",
        "\n",
        "@app.route(\"/process\", methods=[\"POST\"])\n",
        "def process():\n",
        "    data = request.json\n",
        "    query = data.get(\"query\", \"\")\n",
        "    src_language = data.get(\"src_language\", \"en\")\n",
        "    target_language = data.get(\"target_language\", \"en\")\n",
        "\n",
        "    # Process the query\n",
        "    processed_query, answer, tts_audio_path = process_query(query, src_language, target_language)\n",
        "\n",
        "    # Read audio file as base64\n",
        "    with open(tts_audio_path, \"rb\") as audio_file:\n",
        "        audio_content = audio_file.read()\n",
        "\n",
        "    return jsonify({\n",
        "        \"processed_query\": processed_query,\n",
        "        \"answer\": answer,\n",
        "        \"audio_base64\": audio_content.hex()  # Send audio in base64 format\n",
        "    })\n",
        "\n",
        "# Run the Flask app\n",
        "app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CRTtUr2TR5h"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVdrA6cnThG_"
      },
      "outputs": [],
      "source": [
        "!pip install pyttsx3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnkESOCvTOZL"
      },
      "outputs": [],
      "source": [
        "!pip install deep-translator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ6GwmP3UFr5"
      },
      "outputs": [],
      "source": [
        "!pip install gTTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5zndKBKTOST"
      },
      "outputs": [],
      "source": [
        "!pip install flask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wmv03ShhTOPt"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ltl9U0xbOTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCLX9kkpTOL4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxdPTIe-br38"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmUd3Etsbr0X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4l4zp5hCNC9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "previous_dataset_file = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/legal_chatbot_dataset.csv\"  # Replace with your file name\n",
        "previous_df = pd.read_csv(previous_dataset_file)\n",
        "\n",
        "\n",
        "new_data = {\n",
        "    \"Category\": [\n",
        "        \"Accidents and Compensation\",\n",
        "        \"Consumer Rights\",\n",
        "        \"Family Laws\"\n",
        "    ],\n",
        "    \"Query_Phrases\": [\n",
        "        \"What to do after a road accident?; How to claim insurance for an accident?\",\n",
        "        \"What to do if a product is defective?; How can I file a consumer complaint?\",\n",
        "        \"What is the process for divorce?; How to get child custody?\"\n",
        "    ],\n",
        "    \"Problem_Statement\": [\n",
        "        \"Met with a minor accident, want to claim damages.\",\n",
        "        \"Received a faulty product but the seller refuses to replace it.\",\n",
        "        \"Need legal help for divorce and child custody.\"\n",
        "    ],\n",
        "    \"Legal_Provisions\": [\n",
        "        \"Motor Vehicles Act, 1988 (Section 166 - Claims Tribunal)\",\n",
        "        \"Consumer Protection Act, 2019\",\n",
        "        \"Hindu Marriage Act, 1955 (if applicable)\"\n",
        "    ],\n",
        "    \"Procedures\": [\n",
        "        \"1. Take photos of the accident scene. 2. Lodge an FIR. 3. File a claim with your insurer.\",\n",
        "        \"1. Send a written complaint to the seller. 2. File a complaint at the Consumer Disputes Redressal Commission.\",\n",
        "        \"1. Consult a family lawyer. 2. File a divorce petition in the appropriate court.\"\n",
        "    ],\n",
        "    \"FAQs\": [\n",
        "        \"Do I need a lawyer for a motor accident claim?; What documents are needed for an insurance claim?\",\n",
        "        \"Is there a fee for filing a consumer complaint?; What documents are required to file a complaint?\",\n",
        "        \"How long does it take for a divorce case?; Can I get joint custody of my child?\"\n",
        "    ],\n",
        "    \"Resources/Contacts\": [\n",
        "        \"IRDAI consumer helpline: 155255; National Lok Adalat: [Link]\",\n",
        "        \"National Consumer Helpline: 1800-11-4000; Consumer court details: [Link]\",\n",
        "        \"Family court helpline: [Link]; Women's helpline: 181\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "new_df = pd.DataFrame(new_data)\n",
        "\n",
        "\n",
        "updated_df = pd.concat([previous_df, new_df], ignore_index=True)\n",
        "\n",
        "\n",
        "json_file_name = \"updated_legal_chatbot_dataset.json\"\n",
        "updated_df.to_json(json_file_name, orient=\"records\", indent=4)\n",
        "\n",
        "print(f\"Updated dataset created and saved as '{json_file_name}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-NhT9WUwQ64"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"updated_legal_chatbot_dataset.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEDteL2CwQ36"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHqwBn3JwQ1T"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Use your Hugging Face access token (generate from https://huggingface.co/settings/tokens)\n",
        "login(token=\"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\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srUppYPQ0aKB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6uNU9aW0aGq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2g9G2dy2Mpd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLXaDbxL2oMW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXmOLL-U2oJf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UouG8kea2oGf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUzGfrxx2-IQ"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"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\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYvlhS-H2-Eq"
      },
      "outputs": [],
      "source": [
        "repo_url = \"https://huggingface.co/spaces/NiranjanaIlango/SmartLegalNAvigator\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJWKvE_R0aEk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1AT9imr5-09"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe5DS3bgRzHO"
      },
      "source": [
        "gui integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6bj-W1ZSH3h"
      },
      "outputs": [],
      "source": [
        "!pip install gtts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QywvpFt_SOqZ"
      },
      "outputs": [],
      "source": [
        "!pip install googletrans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqxfqVR_RyCP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog, messagebox\n",
        "from gtts import gTTS\n",
        "from googletrans import Translator\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from IPython.display import Audio, display\n",
        "import json\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    messagebox.showerror(\"Error\", \"Torch module is not installed. Please install it using 'pip install torch'.\")\n",
        "    exit()\n",
        "\n",
        "# Initialize Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load Wav2Vec2 ASR Model\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load dataset\n",
        "dataset_file = \"updated_ipc_qa.json\"  # Replace with actual path\n",
        "if os.path.exists(dataset_file):\n",
        "    with open(dataset_file, 'r') as f:\n",
        "        legal_dataset = json.load(f)\n",
        "else:\n",
        "    legal_dataset = []\n",
        "\n",
        "# Function to find relevant answer\n",
        "def find_relevant_context(query):\n",
        "    for entry in legal_dataset:\n",
        "        if query.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return \"Sorry, I couldn't find an exact match for your question.\"\n",
        "\n",
        "# Function to transcribe audio\n",
        "def transcribe_audio(file_path):\n",
        "    audio, rate = sf.read(file_path)\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=rate).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    return asr_processor.decode(predicted_ids[0])\n",
        "\n",
        "# Function to translate text\n",
        "def translate_text(query, src_lang, target_lang):\n",
        "    return translator.translate(query, src=src_lang, dest=target_lang).text\n",
        "\n",
        "# Function to process query\n",
        "def process_query():\n",
        "    query = text_input.get()\n",
        "    src_lang = source_lang.get()\n",
        "    target_lang = target_lang_entry.get()\n",
        "\n",
        "    if query.strip() == \"\":\n",
        "        messagebox.showerror(\"Error\", \"Please enter a query or select an audio file.\")\n",
        "        return\n",
        "\n",
        "    if src_lang != \"en\":\n",
        "        query = translate_text(query, src_lang, \"en\")\n",
        "\n",
        "    answer = find_relevant_context(query)\n",
        "\n",
        "    if target_lang != \"en\":\n",
        "        answer = translate_text(answer, \"en\", target_lang)\n",
        "\n",
        "    # Generate TTS audio\n",
        "    tts = gTTS(answer, lang=target_lang)\n",
        "    tts.save(\"response.mp3\")\n",
        "\n",
        "    output_text.set(answer)\n",
        "    os.system(\"start response.mp3\")  # Play audio\n",
        "\n",
        "# Function to upload and transcribe audio\n",
        "def upload_audio():\n",
        "    file_path = filedialog.askopenfilename(filetypes=[(\"Audio Files\", \"*.wav;*.mp3\")])\n",
        "    if file_path:\n",
        "        transcribed_text = transcribe_audio(file_path)\n",
        "        text_input.set(transcribed_text)\n",
        "\n",
        "# GUI Setup\n",
        "root = tk.Tk()\n",
        "root.title(\"Multilingual Legal Query Translator\")\n",
        "root.geometry(\"500x400\")\n",
        "\n",
        "tk.Label(root, text=\"Enter Query or Upload Audio:\").pack()\n",
        "text_input = tk.StringVar()\n",
        "tk.Entry(root, textvariable=text_input, width=50).pack()\n",
        "tk.Button(root, text=\"Upload Audio\", command=upload_audio).pack()\n",
        "\n",
        "tk.Label(root, text=\"Source Language (e.g., en, hi, ta):\").pack()\n",
        "source_lang = tk.StringVar(value=\"en\")\n",
        "tk.Entry(root, textvariable=source_lang, width=10).pack()\n",
        "\n",
        "tk.Label(root, text=\"Target Language (e.g., en, hi, ta):\").pack()\n",
        "target_lang_entry = tk.StringVar(value=\"en\")\n",
        "tk.Entry(root, textvariable=target_lang_entry, width=10).pack()\n",
        "\n",
        "tk.Button(root, text=\"Translate & Generate Audio\", command=process_query).pack()\n",
        "output_text = tk.StringVar()\n",
        "tk.Label(root, textvariable=output_text, wraplength=450, justify=\"left\").pack()\n",
        "\n",
        "root.mainloop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJKdO6l9ZSXs"
      },
      "outputs": [],
      "source": [
        "!pip install jupyter_http_over_ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vok-fVQrZcOo"
      },
      "outputs": [],
      "source": [
        "!jupyter serverextension enable --py jupyter_http_over_ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZyRq4E7ZtEo"
      },
      "outputs": [],
      "source": [
        "!jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT_nofRY5YTy"
      },
      "source": [
        "GUI implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFf2LBjC5Lee"
      },
      "outputs": [],
      "source": [
        "pip install gradio transformers torch gtts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LiYAxO-Y0Jo"
      },
      "outputs": [],
      "source": [
        "pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GB9cPsm8FFZ"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "# Load the Hugging Face question-answering model\n",
        "qa_model = pipeline(\"question-answering\", model=\"bert-base-uncased\")\n",
        "\n",
        "# Function to process chatbot input and generate text & audio output\n",
        "def chatbot_interface(input_text, language):\n",
        "    context = \"The Indian Constitution, IPC, and CrPC define the laws and rights in India. The Constitution guarantees fundamental rights, IPC defines criminal offenses, and CrPC provides procedural laws.\"\n",
        "\n",
        "    # Get response from the model\n",
        "    response = qa_model(question=input_text, context=context)\n",
        "    response_text = response[\"answer\"]\n",
        "\n",
        "    # Generate speech output\n",
        "    tts = gTTS(response_text, lang=\"en\")  # Adjust language mapping if needed\n",
        "    audio_file = \"response.mp3\"\n",
        "    tts.save(audio_file)\n",
        "\n",
        "    return response_text, audio_file\n",
        "\n",
        "# Define Gradio UI\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Ask a question\"),\n",
        "        gr.Dropdown([\"English\", \"Hindi\", \"Tamil\", \"Telugu\"], label=\"Select Language\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Response\"),\n",
        "        gr.Audio(label=\"Audio Output\")\n",
        "    ],\n",
        "    title=\"Smart Legal Navigator Chatbot\",\n",
        "\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "iface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22iRJI7NA346"
      },
      "source": [
        "version 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXd-9YClA2_E"
      },
      "outputs": [],
      "source": [
        "pip install gradio transformers torch librosa gtts googletrans==4.0.0-rc1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnv0dSkxhiPq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thOfW0LmA7vV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import gradio as gr\n",
        "import librosa\n",
        "from gtts import gTTS\n",
        "from googletrans import Translator\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "\n",
        "# Initialize Google Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Load Speech-to-Text Model (Wav2Vec2)\n",
        "print(\"Loading Wav2Vec2 model...\")\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")  # Fixed\n",
        "\n",
        "# Load Question Answering Model\n",
        "print(\"Loading Question Answering model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Define Legal Context\n",
        "legal_context = \"\"\"\n",
        "The Indian Penal Code (IPC) is the official criminal code of India. It is comprehensive and covers all substantive aspects of criminal law.\n",
        "The Constitution of India is the supreme law of India. It lays down the framework defining fundamental political principles, structures, and duties of government institutions.\n",
        "\"\"\"\n",
        "\n",
        "# Function to transcribe audio to text\n",
        "def transcribe_audio(audio_path):\n",
        "    audio, rate = librosa.load(audio_path, sr=16000)\n",
        "    input_values = asr_processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "    logits = asr_model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = asr_processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Function to translate text\n",
        "def translate_text(query, src_lang, target_lang):\n",
        "    return translator.translate(query, src=src_lang, dest=target_lang).text\n",
        "\n",
        "# Function to process the query and generate response\n",
        "def process_query(query, src_language, target_language):\n",
        "    # Translate the query to English if it's not already\n",
        "    if src_language != \"en\":\n",
        "        query = translate_text(query, src_lang=src_language, target_lang=\"en\")\n",
        "\n",
        "    # Generate an answer from the legal model\n",
        "    response = qa_pipeline(question=query, context=legal_context)\n",
        "    answer = response[\"answer\"]\n",
        "\n",
        "    # Translate the answer back to the user's preferred language\n",
        "    if target_language != \"en\":\n",
        "        answer = translate_text(answer, src_lang=\"en\", target_lang=target_language)\n",
        "\n",
        "    # Generate Text-to-Speech audio\n",
        "    tts = gTTS(answer, lang=target_language)\n",
        "    audio_path = \"response.mp3\"\n",
        "    tts.save(audio_path)\n",
        "\n",
        "    return answer, audio_path\n",
        "\n",
        "# Gradio Interface Function\n",
        "def chatbot_interface(input_text, language):\n",
        "    response_text, response_audio = process_query(input_text, \"en\", language)\n",
        "    return response_text, response_audio\n",
        "\n",
        "# Audio Input Interface\n",
        "def voice_input_interface(audio_file, language):\n",
        "    transcription = transcribe_audio(audio_file)\n",
        "    response_text, response_audio = process_query(transcription, \"en\", language)\n",
        "    return transcription, response_text, response_audio\n",
        "\n",
        "# Create Gradio UI\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## 🏛️ Smart Legal Navigator - Ask Legal Questions on IPC, Constitution, and CrPC\")\n",
        "\n",
        "    with gr.Tab(\"Text Input\"):\n",
        "        text_input = gr.Textbox(label=\"Ask a legal question:\")\n",
        "        language_input = gr.Dropdown([\"en\", \"hi\", \"ta\", \"te\", \"bn\", \"kn\", \"ml\", \"gu\", \"mr\", \"pa\", \"ur\"], label=\"Select Response Language\", value=\"en\")\n",
        "        submit_button = gr.Button(\"Submit\")\n",
        "        text_output = gr.Textbox(label=\"Response\")\n",
        "        audio_output = gr.Audio(label=\"Audio Response\")\n",
        "\n",
        "        submit_button.click(chatbot_interface, inputs=[text_input, language_input], outputs=[text_output, audio_output])\n",
        "\n",
        "    with gr.Tab(\"Voice Input\"):\n",
        "        audio_input = gr.Audio(type=\"filepath\", label=\"Upload an Audio Question\")  # Fixed Error\n",
        "        lang_select = gr.Dropdown([\"en\", \"hi\", \"ta\", \"te\", \"bn\", \"kn\", \"ml\", \"gu\", \"mr\", \"pa\", \"ur\"], label=\"Select Response Language\", value=\"en\")\n",
        "        voice_submit = gr.Button(\"Submit\")\n",
        "        transcribed_text = gr.Textbox(label=\"Transcribed Text\")\n",
        "        voice_text_output = gr.Textbox(label=\"Response\")\n",
        "        voice_audio_output = gr.Audio(label=\"Audio Response\")\n",
        "\n",
        "        voice_submit.click(voice_input_interface, inputs=[audio_input, lang_select], outputs=[transcribed_text, voice_text_output, voice_audio_output])\n",
        "\n",
        "app.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkrgKLjzetPx"
      },
      "outputs": [],
      "source": [
        "!pip install flask flask-cors gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBZgwaMTeuc6"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Enable CORS (Allows VS Code frontend to connect)\n",
        "from flask_cors import CORS\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    data = request.json\n",
        "    user_query = data.get(\"query\", \"\")\n",
        "    language = data.get(\"language\", \"English\")\n",
        "\n",
        "    # 🔹 Your chatbot logic here (replace this with your trained model output)\n",
        "    text_response = f\"Sample response for: {user_query} in {language}\"\n",
        "\n",
        "    # 🔹 Convert text response to speech (Audio Output)\n",
        "    tts = gTTS(text=text_response, lang=\"en\")  # Change `lang` dynamically\n",
        "    audio_path = \"/content/response.mp3\"\n",
        "    tts.save(audio_path)\n",
        "\n",
        "    return jsonify({\n",
        "        \"text_output\": text_response,\n",
        "        \"audio_output\": audio_path\n",
        "    })\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcq4ImI0e7bm"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q8GpgRuKzzv"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Paths\n",
        "constitution_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json\"\n",
        "crpc_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json\"\n",
        "ipc_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/ipc_qa.json\"  # You repeated constitution before\n",
        "\n",
        "# Load JSON files\n",
        "def load_qa(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "constitution_data = load_qa(constitution_path)\n",
        "crpc_data = load_qa(crpc_path)\n",
        "ipc_data = load_qa(ipc_path)\n",
        "\n",
        "# Combine all QAs\n",
        "all_data = constitution_data + crpc_data + ipc_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc3eUP1fLy8f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(all_data)\n",
        "df = df.dropna()  # Remove any rows with missing data\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRsvpM1HL2xG"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['question'])\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X, df['answer'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2PHekktL54z"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, '/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/legal_bot_model.pkl')\n",
        "joblib.dump(vectorizer, '/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/vectorizer.pkl')\n",
        "\n",
        "print(\"✅ Saved model & vectorizer to Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qlpOXQsCs-F"
      },
      "outputs": [],
      "source": [
        "# Load model and vectorizer from Drive\n",
        "import joblib\n",
        "\n",
        "model = joblib.load('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/legal_bot_model.pkl')\n",
        "vectorizer = joblib.load('/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/vectorizer.pkl')\n",
        "\n",
        "# Chat function\n",
        "def get_legal_response(question):\n",
        "    vec = vectorizer.transform([question])\n",
        "    response = model.predict(vec)\n",
        "    return response[0]\n",
        "\n",
        "# Try it\n",
        "user_input = input(\"Ask your legal question: \")\n",
        "print(\"Bot:\", get_legal_response(user_input))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXyJenoZCs6p"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def chatbot_interface(question):\n",
        "    vec = vectorizer.transform([question])\n",
        "    response = model.predict(vec)\n",
        "    return response[0]\n",
        "\n",
        "demo = gr.Interface(fn=chatbot_interface,\n",
        "                    inputs=\"text\",\n",
        "                    outputs=\"text\",\n",
        "                    title=\" Smart Legal Navigator\",\n",
        "                    description=\"Ask any legal question based on Constitution, IPC, or CrPC.\")\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW-lrKEZCs4N"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# ✅ Update your exact file paths here:\n",
        "constitution_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json\"\n",
        "crpc_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json\"\n",
        "ipc_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/ipc_qa.json\"\n",
        "\n",
        "# Load all files\n",
        "def load_qa(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "constitution_data = load_qa(constitution_path)\n",
        "crpc_data = load_qa(crpc_path)\n",
        "ipc_data = load_qa(ipc_path)\n",
        "\n",
        "# Combine all\n",
        "all_data = constitution_data + crpc_data + ipc_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbCqTiEeNt7y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Build DataFrame\n",
        "df = pd.DataFrame(all_data)\n",
        "df = df.dropna()\n",
        "\n",
        "# Train\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['question'])\n",
        "model = MultinomialNB()\n",
        "model.fit(X, df['answer'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q55d-uGGNt4O"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/legal_bot_model.pkl\"\n",
        "vectorizer_path = \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/vectorizer.pkl\"\n",
        "\n",
        "joblib.dump(model, model_path)\n",
        "joblib.dump(vectorizer, vectorizer_path)\n",
        "\n",
        "print(\"✅ Model & vectorizer saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvgtiqizNt1h"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Load model again (optional if already in memory)\n",
        "model = joblib.load(model_path)\n",
        "vectorizer = joblib.load(vectorizer_path)\n",
        "\n",
        "def get_legal_response(user_input):\n",
        "    if not user_input.strip():\n",
        "        return \"❗ Please ask a valid legal question.\"\n",
        "    vec = vectorizer.transform([user_input])\n",
        "    response = model.predict(vec)\n",
        "    return response[0]\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=get_legal_response,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Ask your legal question here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"⚖️ Smart Legal Navigator\",\n",
        "    description=\"Ask questions from Indian Constitution, IPC, and CrPC.\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKIijMDnNty7"
      },
      "outputs": [],
      "source": [
        "!pip install gradio googletrans==4.0.0-rc1 gTTS SpeechRecognition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxQ168OVOH6P"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "def translate_text(text, dest_lang='en'):\n",
        "    try:\n",
        "        translated = translator.translate(text, dest=dest_lang)\n",
        "        return translated.text\n",
        "    except:\n",
        "        return \"❗ Translation error. Try again.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLXmAd5NOH37"
      },
      "outputs": [],
      "source": [
        "def get_multilingual_response(user_input, user_lang='en'):\n",
        "    if not user_input.strip():\n",
        "        return \"Please ask a valid legal question.\", None\n",
        "\n",
        "    # Translate question to English\n",
        "    question_in_english = translator.translate(user_input, dest='en').text\n",
        "\n",
        "    # Predict in English\n",
        "    vec = vectorizer.transform([question_in_english])\n",
        "    predicted_answer_en = model.predict(vec)[0]\n",
        "\n",
        "    # Translate answer back to user language\n",
        "    translated_answer = translator.translate(predicted_answer_en, dest=user_lang).text\n",
        "\n",
        "    # Convert to voice (mp3)\n",
        "    tts = gTTS(translated_answer, lang=user_lang)\n",
        "    tts.save(\"response.mp3\")\n",
        "\n",
        "    return translated_answer, \"response.mp3\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaEz16bdOH07"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "lang_options = {\n",
        "    \"English\": \"en\",\n",
        "    \"Tamil\": \"ta\",\n",
        "    \"Hindi\": \"hi\",\n",
        "    \"Telugu\": \"te\",\n",
        "    \"Malayalam\": \"ml\",\n",
        "    \"Kannada\": \"kn\",\n",
        "    \"Marathi\": \"mr\",\n",
        "    \"Bengali\": \"bn\",\n",
        "    \"Gujarati\": \"gu\",\n",
        "    \"Punjabi\": \"pa\",\n",
        "    \"Urdu\": \"ur\"\n",
        "}\n",
        "\n",
        "def chat_interface(text_input, lang_choice):\n",
        "    lang_code = lang_options.get(lang_choice, \"en\")\n",
        "    return get_response_with_voice(text_input, lang_code)\n",
        "\n",
        "gr.Interface(\n",
        "    fn=chat_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"🗣️ Ask your legal question\"),\n",
        "        gr.Dropdown(choices=list(lang_options.keys()), label=\"🌐 Language\", value=\"English\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"📜 Answer\"),\n",
        "        gr.Audio(label=\"🔊 Speak\")\n",
        "    ],\n",
        "    title=\"⚖️ Smart Legal Navigator - Multilingual + Voice\",\n",
        "    description=\"Get legal answers in your preferred language with voice.\"\n",
        ").launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ_UY0C5OO68"
      },
      "outputs": [],
      "source": [
        "def chat_interface(text_input, lang_choice):\n",
        "    try:\n",
        "        lang_code = lang_options.get(lang_choice, \"en\")\n",
        "        answer, audio_path = get_response_with_voice(text_input, lang_code)\n",
        "        return answer, audio_path\n",
        "    except Exception as e:\n",
        "        return f\"❗ Error: {str(e)}\", None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_kUE93aOrX2"
      },
      "outputs": [],
      "source": [
        "gr.Interface(\n",
        "    fn=chat_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"🗣️ Ask your legal question\"),\n",
        "        gr.Dropdown(choices=list(lang_options.keys()), label=\"🌐 Language\", value=\"English\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"📜 Answer\"),\n",
        "        gr.Audio(label=\"🔊 Speak\")\n",
        "    ],\n",
        "    title=\"⚖️ Smart Legal Navigator - Multilingual + Voice\",\n",
        "    description=\"Get legal answers in your preferred language with voice.\"\n",
        ").launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUrPGa3K6VSW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6axWU1i6lNA"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# Translate to English\n",
        "translated = GoogleTranslator(source='auto', target='en').translate(\"நீங்கள் எப்படி இருக்கிறீர்கள்?\")\n",
        "\n",
        "# Translate to Tamil\n",
        "response = GoogleTranslator(source='en', target='ta').translate(\"I am fine, thank you!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muRNRJeuOrUe"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install core libraries\n",
        "!pip install -q transformers datasets gradio gtts googletrans==4.0.0-rc1 pyttsx3 speechrecognition torchaudio librosa deep-translator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhrJInubPw_9"
      },
      "outputs": [],
      "source": [
        "# View current packages\n",
        "!pip list | grep -E \"httpx|httpcore|websockets|fsspec\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUSuI0pwPw8d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def load_datasets():\n",
        "    files = [\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/ipc_qa.json\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/crpc_qa.json\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/Smart legal navigator/constitution_qa.json\"\n",
        "    ]\n",
        "    combined = []\n",
        "    for file in files:\n",
        "        with open(file, \"r\") as f:\n",
        "            combined.extend(json.load(f))\n",
        "    return combined\n",
        "\n",
        "combined_dataset = load_datasets()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OLhlNrH7T7b"
      },
      "outputs": [],
      "source": [
        "# Uninstall numpy completely\n",
        "!pip uninstall -y numpy\n",
        "\n",
        "# Reinstall a stable version compatible with other packages\n",
        "!pip install numpy==1.23.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63IhRpjpQl4V"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "import gradio as gr\n",
        "\n",
        "def find_answer(query, dataset):\n",
        "    for entry in dataset:\n",
        "        if query.lower() in entry[\"question\"].lower():\n",
        "            return entry[\"answer\"]\n",
        "    return \"Sorry, I don't have an answer.\"\n",
        "\n",
        "def multilingual_chatbot(user_input, target_lang):\n",
        "    translated_in = GoogleTranslator(source='auto', target='en').translate(user_input)\n",
        "    answer_en = find_answer(translated_in, combined_dataset)\n",
        "    answer_translated = GoogleTranslator(source='en', target=target_lang).translate(answer_en)\n",
        "    return answer_translated\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=multilingual_chatbot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Ask your question\"),\n",
        "        gr.Dropdown(choices=[\"en\", \"ta\", \"hi\", \"te\", \"ml\", \"bn\", \"gu\"], label=\"Select Output Language\", value=\"en\")\n",
        "    ],\n",
        "    outputs=\"textbox\",\n",
        "    title=\"Smart Legal Navigator\",\n",
        "    description=\"Ask legal questions in any language. Get translated voice/text answers.\"\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pflzx3o5Zh3",
        "outputId": "51c357ae-e1da-415b-d1e0-4e9dff746e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: httpx 0.28.1\n",
            "Uninstalling httpx-0.28.1:\n",
            "  Successfully uninstalled httpx-0.28.1\n",
            "Found existing installation: httpcore 1.0.9\n",
            "Uninstalling httpcore-1.0.9:\n",
            "  Successfully uninstalled httpcore-1.0.9\n",
            "\u001b[33mWARNING: Skipping googletrans as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: gradio 5.49.1\n",
            "Uninstalling gradio-5.49.1:\n",
            "  Successfully uninstalled gradio-5.49.1\n",
            "\u001b[33mWARNING: Skipping deep-translator as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5.tar.gz (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting httpx==0.28.1\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpcore==0.16.3\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx==0.28.1) (2025.10.5)\n",
            "INFO: pip is looking at multiple versions of httpx to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install httpcore==0.16.3 and httpx==0.28.1 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested httpcore==0.16.3\n",
            "    httpx 0.28.1 depends on httpcore==1.*\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting gradio==3.50.2\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.121.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.6.4)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx (from gradio==3.50.2)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.36.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.50.2)\n",
            "  Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.10.0)\n",
            "Collecting numpy~=1.0 (from gradio==3.50.2)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.2.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==3.50.2)\n",
            "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (6.0.3)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.32.4)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2) (0.38.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2)\n",
            "  Downloading websockets-11.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==0.6.1->gradio==3.50.2) (2025.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (2.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.0->gradio==3.50.2) (2025.10.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.16.0)\n",
            "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->gradio==3.50.2) (0.49.3)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi->gradio==3.50.2) (0.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==3.50.2) (4.11.0)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.50.2)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50.2) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->gradio==3.50.2) (1.3.1)\n",
            "Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m127.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, pillow, numpy, markupsafe, httpcore, aiofiles, httpx, gradio-client, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.13.3\n",
            "    Uninstalling gradio_client-1.13.3:\n",
            "      Successfully uninstalled gradio_client-1.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-genai 1.49.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-adk 1.17.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 11.0.3 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 gradio-3.50.2 gradio-client-0.6.1 httpcore-1.0.9 httpx-0.28.1 markupsafe-2.1.5 numpy-1.26.4 pillow-10.4.0 websockets-11.0.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7158950d197b4aaf989973df4af9521a",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.10.5)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n"
          ]
        }
      ],
      "source": [
        "# Clean up broken/conflicting packages\n",
        "!pip uninstall -y numpy httpx httpcore googletrans gradio deep-translator\n",
        "\n",
        "# Reinstall with compatible versions\n",
        "!pip install numpy==1.23.5\n",
        "!pip install httpx==0.28.1 httpcore==0.16.3\n",
        "!pip install gradio==3.50.2\n",
        "!pip install deep-translator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W60l8jpM5ZeV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e1n5SAd66VV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdEvirE66RX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07bdc163f076437090841d4360dae9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094c44eba03549b69dc30436881fdecc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5d67417a8145bd82c5c199388ebf46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d560902e88141ac9812808c91696a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6238a8920bef4e23989f0c7cfafd7280",
            "placeholder": "​",
            "style": "IPY_MODEL_fa80e3c612804687bdd9cf6ccf9ae453",
            "value": " 570/570 [00:00&lt;00:00, 16.0kB/s]"
          }
        },
        "2312e76ca87b40b1a5068b13ae9f86a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e8491cd4ee1471094733104e8f79f44",
            "placeholder": "​",
            "style": "IPY_MODEL_b0c4d6eeae67487eb7ed181c18e93fcb",
            "value": "vocab.txt: 100%"
          }
        },
        "2dc266b28c734a938c800be0ead84a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6225b685385640cba44aa19243fe818c",
              "IPY_MODEL_c8f5d0ce8faf4248a55397ec2e8a67cf",
              "IPY_MODEL_ed4247b86ffe4db6ba1bab72ccb47165"
            ],
            "layout": "IPY_MODEL_b853d6a1f086406ab951d0040c601603"
          }
        },
        "31baf0d747964e95a752678ac9af5801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a3db46550264d03a0e080e190ddf7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b9310f4aab74b05b45f95b913116f01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d39ae8cc9fa4fab9b96decea548e89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fe5530f92334086915795571dafc732": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48291020719f43db9b7bbbff13728147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdbda4372f9f4516897d13373258b2df",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87de80df0ec749479f584f7894df6d36",
            "value": 231508
          }
        },
        "4aa8208f259d4dabb29b36a0dd2f0d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5532a6138f4519855f817c61bf0f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe67a366f4114dd4969844e6c54fabaf",
            "placeholder": "​",
            "style": "IPY_MODEL_0c5d67417a8145bd82c5c199388ebf46",
            "value": " 440M/440M [00:05&lt;00:00, 142MB/s]"
          }
        },
        "4ca4cadf5d044777994becef379b0f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa8d75ee30b2490386a85a3383a4bcbe",
            "placeholder": "​",
            "style": "IPY_MODEL_86b7d4931f0c491293fae2fd85479ec5",
            "value": " 466k/466k [00:00&lt;00:00, 8.72MB/s]"
          }
        },
        "4f1d18c42a9f40a985e468fe7f87cd9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d12d2a1ef0493b9c929e50c0f8f397",
            "placeholder": "​",
            "style": "IPY_MODEL_31baf0d747964e95a752678ac9af5801",
            "value": "config.json: 100%"
          }
        },
        "5e639e0a1e374de19ed2bbadc47b4e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "614a735ad83a4f04af6df7d54b563868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9913a1ab84fb49b6aaa3a08518f0d471",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_968c1bd1e50c475ca89603458ceb71d7",
            "value": 440449768
          }
        },
        "6225b685385640cba44aa19243fe818c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879a3fa37615474085ea1c00b7bf6356",
            "placeholder": "​",
            "style": "IPY_MODEL_3d39ae8cc9fa4fab9b96decea548e89a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6238a8920bef4e23989f0c7cfafd7280": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6386c07cf04e4ee2963ab08331656612": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e6f9f9eee84e2fa8bbcf674be1efa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d782239068ae496ba5eb8edf8bf9dd0f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a3db46550264d03a0e080e190ddf7f2",
            "value": 466062
          }
        },
        "762002af13a94fe4897240599391f097": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7984a58e7f7d4c6bb3e4b3e4d8fee480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86b7d4931f0c491293fae2fd85479ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "879a3fa37615474085ea1c00b7bf6356": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87de80df0ec749479f584f7894df6d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e8491cd4ee1471094733104e8f79f44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "968c1bd1e50c475ca89603458ceb71d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98c131e903db4fed89dcbd2bbeb56839": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9913a1ab84fb49b6aaa3a08518f0d471": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1581138b6a4d3bb95bd0e6e9de1d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af6f14bba8524fa2877ae2712b6680f7",
              "IPY_MODEL_614a735ad83a4f04af6df7d54b563868",
              "IPY_MODEL_4b5532a6138f4519855f817c61bf0f8f"
            ],
            "layout": "IPY_MODEL_5e639e0a1e374de19ed2bbadc47b4e8a"
          }
        },
        "a89381ca326c4f619318a2142f547928": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f1d18c42a9f40a985e468fe7f87cd9b",
              "IPY_MODEL_f9a8af2dc193429aaa0e541f9c8068dd",
              "IPY_MODEL_1d560902e88141ac9812808c91696a4f"
            ],
            "layout": "IPY_MODEL_4aa8208f259d4dabb29b36a0dd2f0d8f"
          }
        },
        "a9d12d2a1ef0493b9c929e50c0f8f397": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af6f14bba8524fa2877ae2712b6680f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c131e903db4fed89dcbd2bbeb56839",
            "placeholder": "​",
            "style": "IPY_MODEL_7984a58e7f7d4c6bb3e4b3e4d8fee480",
            "value": "model.safetensors: 100%"
          }
        },
        "b0c4d6eeae67487eb7ed181c18e93fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b20e26372e4148f18a1998159331bfbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b853d6a1f086406ab951d0040c601603": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce5aebd926d41f195562108b2cdb1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_094c44eba03549b69dc30436881fdecc",
            "placeholder": "​",
            "style": "IPY_MODEL_c1476d2312034d69a906a984b6e720b2",
            "value": "tokenizer.json: 100%"
          }
        },
        "bdbda4372f9f4516897d13373258b2df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1476d2312034d69a906a984b6e720b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4b9833be64c4bd187b21958473c0bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8f5d0ce8faf4248a55397ec2e8a67cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed8f442694564abd915094745aa2a8b9",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d235eaee694748718955e86791b3334b",
            "value": 48
          }
        },
        "cd6524d43c694659a055287bb6fc1080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bce5aebd926d41f195562108b2cdb1b0",
              "IPY_MODEL_66e6f9f9eee84e2fa8bbcf674be1efa7",
              "IPY_MODEL_4ca4cadf5d044777994becef379b0f28"
            ],
            "layout": "IPY_MODEL_6386c07cf04e4ee2963ab08331656612"
          }
        },
        "d235eaee694748718955e86791b3334b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d782239068ae496ba5eb8edf8bf9dd0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db36c2fd6b72442ebc1fd0f24d6b5724": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5f921278da4d30b7dea85e0d549f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2312e76ca87b40b1a5068b13ae9f86a1",
              "IPY_MODEL_48291020719f43db9b7bbbff13728147",
              "IPY_MODEL_e7c5f4be346d49919cabf2b09eb19440"
            ],
            "layout": "IPY_MODEL_3b9310f4aab74b05b45f95b913116f01"
          }
        },
        "e7c5f4be346d49919cabf2b09eb19440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07bdc163f076437090841d4360dae9cf",
            "placeholder": "​",
            "style": "IPY_MODEL_762002af13a94fe4897240599391f097",
            "value": " 232k/232k [00:00&lt;00:00, 3.65MB/s]"
          }
        },
        "ed4247b86ffe4db6ba1bab72ccb47165": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db36c2fd6b72442ebc1fd0f24d6b5724",
            "placeholder": "​",
            "style": "IPY_MODEL_c4b9833be64c4bd187b21958473c0bd3",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.06kB/s]"
          }
        },
        "ed8f442694564abd915094745aa2a8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a8af2dc193429aaa0e541f9c8068dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b20e26372e4148f18a1998159331bfbf",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fe5530f92334086915795571dafc732",
            "value": 570
          }
        },
        "fa80e3c612804687bdd9cf6ccf9ae453": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa8d75ee30b2490386a85a3383a4bcbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe67a366f4114dd4969844e6c54fabaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}